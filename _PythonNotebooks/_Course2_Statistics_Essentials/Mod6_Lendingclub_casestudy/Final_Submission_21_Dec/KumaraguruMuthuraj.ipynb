{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Club Case Study\n",
    "## Authors\n",
    "### Siddakka Saptasagare\n",
    "### Kumaraguru Muthuraj\n",
    "\n",
    "## Business Understanding\n",
    "**You work for a consumer finance company which specialises in lending various types of loans to urban customers. When the company receives a loan application, the company has to make a decision for loan approval based on the applicant’s profile. Two types of risks are associated with the bank’s decision:**\n",
    "- If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n",
    "- If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company\n",
    "<p>\n",
    "<img src =\"https://cdn.upgrad.com/UpGrad/temp/7afbce98-8ecc-41c6-96d8-981cba7d343f/Loan_image.png\" alt='Figure 1' style=\"width:600px;\">\n",
    "<center> <b>Approval - Rejection flow</b> </center> \n",
    " </br>  \n",
    "</p>\n",
    "\n",
    "**When a person applies for a loan, there are two types of decisions that could be taken by the company:**\n",
    "\n",
    "- Loan accepted: If the company approves the loan, there are 3 possible scenarios described below:\n",
    "\n",
    "> Fully paid: Applicant has fully paid the loan (the principal and the interest rate)\n",
    "\n",
    "> Current: Applicant is in the process of paying the instalments, i.e. the tenure of the loan is not yet completed. These candidates are not labelled as 'defaulted'.\n",
    "\n",
    "> Charged-off: Applicant has not paid the instalments in due time for a long period of time, i.e. he/she has defaulted on the loan \n",
    "\n",
    "- Loan rejected: The company had rejected the loan (because the candidate does not meet their requirements etc.). Since the loan was rejected, there is no transactional history of those applicants with the company and so this data is not available with the company (and thus in this dataset)\n",
    "\n",
    "## Business Objectives\n",
    "**This company is the largest online loan marketplace, facilitating personal loans, business loans, and financing of medical procedures. Borrowers can easily access lower interest rate loans through a fast online interface.**\n",
    "\n",
    "**The company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default.  The company can utilise this knowledge for its portfolio and risk assessment.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we solving for?\n",
    "**Lending Club, being headquartered in SFO, CA lends money for cheap interest rates for three major reasons, namely medical, personal and business loans.**\n",
    "\n",
    "**The history of borrowers between 2007 and 2011 provided will be used to do statistical analysis and provide insights on what parameters of the borrower are related to defaulting. This will help Lending Club avoid lending money to these customers or reduce the loan amount or increase the interest rate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did we solve?\n",
    "**We have done extensive EDA on all the parameters in the loan.csv by relating to the meaning in data dictionary. After doing analysis, we have provided multi-perspective analyis and observe the patterns.**\n",
    "\n",
    "**Once we establish the pattern, we record our conclusion and recommend what LC should do. Every cell(or group of cells) is dedicated to a set of parameters that we analyze. These indicate the factors impacting defaulting nature of customers.**\n",
    "\n",
    "**We have used different visualizations to perceive the pattern powerfully which leads to decisions.**\n",
    "\n",
    "## Executive summary of loan and customer parameters that are risk indicators\n",
    "\n",
    "\n",
    "### Charged-off and paid-off loans\n",
    "#### Risk 1 - Loan grades E, F and G are higher risk loans. Looks like LC is already charging higher interest rate to recover faster. When LC issues a high loan amount they have to look at other risk factors listed further. A, B, C and D have high risk of defaulting.\n",
    "#### Risk 2 - Most of the loans above interest rate 15% are at the risk of being charged-off. If interest rate is kept lower in the range of 8 - 11%, the risk of charging-off reduces.\n",
    "#### Risk 3 - Debt consolidation, credit card, small business, other and home improvement reasons have highest charged off debts. \n",
    "#### Risk 4 - Rental and Mortage home dwellers have higher charged-off status than owners. A customer from rental home is risky, followed by mortgagers.\n",
    "#### Risk 5 - The ratio of bankruptcy counts to none is higher for charged-off customers. If a customer declared bankruptcy before, he is more likely to default.\n",
    "#### Risk 6 - States grouped based on geography, indicate West region has taken more loans. A loan request from western states is risky, especially California. \n",
    "\n",
    "\n",
    "### Charged-off loans by Top 4 - States, months and  purposes.\n",
    "#### Risk 7 - For either terms, if the interest rate is reduced, defaulting behavior can be reduced.\n",
    "#### Risk 8 - Giving loan to a customer under the Top 4 criteria with income less than 40K and grade A, B and C is risky. \n",
    "#### Risk 9 - Issuing loans in Sep-Dec (specifically Nov and Dec), for the 4 states with debt consolidation as purpose is risky. Customers ask for loan with debt consolidation as a reason in the 4 (especially California) states and default maximum. Towards the end of the year, as celebration begins, customers prepare to take the loan and default.\n",
    "#### Risk 10 - Lending money to customers fitting top 4 criteria with employment length less than 2 years is risky.\n",
    "#### Risk 11 - If a customer fitting top 4 criteria in rental home, applies for loan with purpose debt consolidation in the last 4 months, its risky.\n",
    "#### Risk 12 - When loans are issued without source verification, they are very risky.\n",
    "#### Risk 13 - Risky to give loans to rental customers with higher DTI.\n",
    "\n",
    "\n",
    "\n",
    "### The insights are provided step-by-step in the form of a story, to grasp the most important customer parameters impacting loan defaulting tendency. There are 3 major sections:\n",
    "### A) Cleaning and preparing data.  \n",
    "### B) Extensive EDA and multi-perspective visualizations with insights and conclusions for the entire year.\n",
    "### C) Risk analysis with TopN criteria for charged-off loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section (A) Cleaning and preparing data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load the required libraries, open the loan.csv and cleanup data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required python libraries\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'loan.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1feddc5d215d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'loan.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mloan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# extracting the files using 'extracall' method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'loan.zip'"
     ]
    }
   ],
   "source": [
    "#Loading and Extracting the loan zip file\n",
    "#importing the zipfile library required to extract and read the zip file\n",
    "#MAKE SURE THE loan.csv and loan.zip are NOT OPEN.\n",
    "import zipfile as zf\n",
    "filename= 'loan.zip'\n",
    "loan = zf.ZipFile(filename,'r')\n",
    "# extracting the files using 'extracall' method\n",
    "print(loan.printdir())\n",
    "loan.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe by using the csv file present in the zip file\n",
    "df = pd.read_csv(loan.open('loan.csv'),low_memory=False, parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of the dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We observed that there are more then 100 columns present in our dataframe\n",
    "#Lets use set_option to display all the columns of df\n",
    "pd.set_option('display.max_columns', 200)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets drop the columns of the df having all NULL or SAME values.\n",
    "#If half the rows in a column is empty drop the column.\n",
    "thresh = len(df) * .5 \n",
    "df.dropna(thresh = thresh, axis = 1, inplace = True)\n",
    "print(df.shape)\n",
    "# Lets reset the row index from default to id\n",
    "df.set_index(['id'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the null values of data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the following step, we see that all of the columns have their data filled. But if you look at the values visually, we see that they are repeated to the extent where it doesn't give any perspective. Drop these columns! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['pymnt_plan'].value_counts())\n",
    "#print(df['url'].value_counts())\n",
    "\n",
    "#CAN do mining on 'desc' text, but the reasons are already condensed in the 'purpose' column.\n",
    "#print(df['desc'].value_counts())\n",
    "#print(df['initial_list_status'].value_counts())\n",
    "#print(df['collections_12_mths_ex_med'].value_counts())\n",
    "#print(df['policy_code'].value_counts())\n",
    "#print(df['application_type'].value_counts())\n",
    "#print(df['acc_now_delinq'].value_counts())\n",
    "#print(df['delinq_amnt'].value_counts())\n",
    "#print(df['tax_liens'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We were recommended by stake holders to remove charged-off loan records and the columns related to customer information - after loan is issued in Part 2. Part 1 has columns for which the values are either 0 or same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1\n",
    "#Let's drop the irrelevent columns to get proper and structured data frame for analysis\n",
    "#We are dropping the columns because the values of the column or either \"0\" or same\n",
    "df.drop(['pymnt_plan','url','desc','initial_list_status','collections_12_mths_ex_med','policy_code','application_type','acc_now_delinq','chargeoff_within_12_mths','delinq_amnt','tax_liens'], inplace=True, axis=1)\n",
    "\n",
    "#Part 2 - Stake holders asked us to remove these columns because these are filled in after the loan is issued.\n",
    "df.drop(['inq_last_6mths', 'delinq_2yrs', 'open_acc', 'earliest_cr_line', 'total_acc', 'out_prncp', 'pub_rec', 'revol_bal',\\\n",
    "        'out_prncp_inv', 'revol_util', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', \\\n",
    "         'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d'], \\\n",
    "        inplace=True, axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization and data formating of columns.\n",
    "- Create dervived variables to extract more insights and check the factors for high risky loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets replace special character and convert interest rate and revol_util to float\n",
    "df.int_rate = df['int_rate'].str.strip('%').astype('float').round()\n",
    "#df.revol_util = df['revol_util'].str.strip('%').astype('float').round()\n",
    "\n",
    "getTerm = lambda x: x.strip().split(' ')[0]\n",
    "df['term'] = (df['term'].apply(getTerm)).astype('int')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do the data imputation for emp_title and emp_length columns\n",
    "#Fill the values with mode of the data, as it makes more sense to do this.\n",
    "df.emp_title = df.emp_title.fillna(df.emp_title.mode()[0])\n",
    "df.emp_length = df.emp_length.fillna(df.emp_length.mode()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need dates so that we can do some arithmetic later.\n",
    "def getDate(x):\n",
    "    x = str(x).strip()\n",
    "    ret = datetime(1900, 1, 1).date()\n",
    "    if not x:\n",
    "        return ret\n",
    "    elif x.upper() == str(float('nan')).upper():\n",
    "        return ret\n",
    "    else:    \n",
    "        ret = datetime.strptime(str(x), '%b-%y').date()\n",
    "    return ret\n",
    "\n",
    "df['issue_d'] = df['issue_d'].apply(getDate)\n",
    "df['issue_year'] = df['issue_d'].apply(lambda x: str(x.year))\n",
    "df['issue_month'] = df['issue_d'].apply(lambda x: x.strftime('%b').upper())\n",
    "\n",
    "#print (df[['issue_d_tmp', 'issue_year', 'issue_month']])\n",
    "\n",
    "#def MMM_YY_2_Date(x):\n",
    "#    y = datetime.strptime(x, '%b-%y')\n",
    "#    _2019Date = datetime(2019, 1, 1)\n",
    "#    if y > _2019Date:\n",
    "#        y = y - relativedelta(years = 100)\n",
    "#    return y.date()\n",
    "\n",
    "#df['earliest_cr_line'] = df['earliest_cr_line'].apply(MMM_YY_2_Date)\n",
    "#df['earl_cr_line_month'] = df['earliest_cr_line'].apply(lambda x: x.strftime('%b'))\n",
    "#df['earl_cr_line_year'] = df['earliest_cr_line'].apply(lambda x: str(x.year))\n",
    "\n",
    "#df['credit_history'] = ((df['issue_d'] - df['earliest_cr_line']) / np.timedelta64(1, 'Y')).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets standardize the empl_length column\n",
    "# Less than 1 year be considered 0\n",
    "def currentEmploymentLength(y):\n",
    "    if y == None:\n",
    "        return \"invalid\"\n",
    "    y = y.strip()\n",
    "    if (y.find(\"< 1\") != -1):\n",
    "        return 0\n",
    "    result = re.findall(\"\\d+\", y)\n",
    "    if result == None:\n",
    "        return \"invalid\"\n",
    "    return int(result[0])\n",
    "\n",
    "#Check unique values to know pattern\n",
    "#print(df.emp_length.value_counts())\n",
    "df.emp_length = df.emp_length.apply(currentEmploymentLength)\n",
    "#Validate if the values are as expected\n",
    "#print(df.emp_length.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['last_credit_pull_month'] = df.last_credit_pull_d.str.split('-').str[0].str.upper()\n",
    "#df['last_credit_pull_Year'] = df.last_credit_pull_d.str.split('-').str[1]\n",
    "\n",
    "#def getLastPaymentDate(x):\n",
    "#    x = str(x).strip()\n",
    "#    ret = datetime(1900, 1, 1).date()\n",
    "#    if not x:\n",
    "#        return ret\n",
    "#    elif x.upper() == str(float('nan')).upper():\n",
    "#        return ret\n",
    "#    else:    \n",
    "#        ret = datetime.strptime(str(x), '%b-%y').date()\n",
    "#    return ret\n",
    "    \n",
    "#df['last_pymnt_d'] = df['last_pymnt_d'].apply(getLastPaymentDate)\n",
    "#df['last_pymnt_d_tmp'].head()\n",
    "\n",
    "#Can we get the month and year string?\n",
    "#df['last_pymnt_month'] = df['last_pymnt_d'].apply(lambda x: x.strftime('%b'))\n",
    "#df['last_pymnt_year'] = df['last_pymnt_d'].apply(lambda x: x.year)\n",
    "\n",
    "#df[['last_pymnt_d_tmp', 'last_pymnt_month', 'last_pymnt_year']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower case\n",
    "df['loan_status'] = df['loan_status'].apply(str.lower)\n",
    "df['verification_status'] = df['verification_status'].apply(str.lower)\n",
    "df['purpose'] = df['purpose'].apply(str.lower)\n",
    "df['title'] = df['title'].astype(str).apply(str.lower)\n",
    "\n",
    "#EMI as a percent of monthly income\n",
    "df['emi_income_percent'] = (df['installment'] / (df['annual_inc'] /12)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the details of addr_state.\n",
    "# What if we group states together into regions according to starndard terminology and see if any pattern emerges.\n",
    "# Pick a simple standard way to group States to Regions.\n",
    "print(df.addr_state.unique())\n",
    "\n",
    "# lets create Region column depedning on the state column value\n",
    "# https://www.ducksters.com/geography/us_states/us_geographical_regions.php\n",
    "west = ['CA', 'OR', 'UT','WA', 'CO', 'NV', 'AK', 'MT', 'HI', 'WY', 'ID']\n",
    "south_west = ['AZ', 'TX', 'NM', 'OK']\n",
    "south_east = ['GA', 'NC', 'VA', 'FL', 'KY', 'SC', 'LA', 'AL', 'WV', 'DC', 'AR', 'DE', 'MS', 'TN' ]\n",
    "mid_west = ['IL', 'MO', 'MN', 'OH', 'WI', 'KS', 'MI', 'SD', 'IA', 'NE', 'IN', 'ND']\n",
    "north_east = ['CT', 'NY', 'PA', 'NJ', 'RI','MA', 'MD', 'VT', 'NH', 'ME']\n",
    "\n",
    "df['Region']= np.nan\n",
    "\n",
    "def map_region(state):\n",
    "    if state in west:\n",
    "        return 'west'\n",
    "    elif state in south_west:\n",
    "        return 'south_west'\n",
    "    elif state in south_east:\n",
    "        return 'south_east'\n",
    "    elif state in mid_west:\n",
    "        return 'mid_west'\n",
    "    elif state in north_east:\n",
    "        return 'north_east'\n",
    "df['Region'] = df['addr_state'].apply(map_region)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the different loan and consumer attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "for col in cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section (B) Extensive EDA and multi-perspective visualizations with insights and conclusions for the most representative year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Lets look at the distribution of loan amount, funded amount and interest rates.\n",
    "#### Objective: What is the shape of the distribution for loan amount, funded amount and interest rates?\n",
    "\n",
    "#### Observation: From the distribution plots we can conclude that the loan amount applied for, loan amount funded and the interest rate are bell shaped but skewed to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_amount = df.loan_amnt.values\n",
    "funded_amnt = df.funded_amnt_inv.values\n",
    "Interest_Rate =df.int_rate.values\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15,15))\n",
    "\n",
    "# Lets draw the distribution plot for the above subsets\n",
    "sns.distplot(loan_amount, ax=ax[0], color='red')\n",
    "sns.distplot(funded_amnt, ax=ax[1], color='green')\n",
    "sns.distplot(Interest_Rate, ax=ax[2], color='orange')\n",
    "\n",
    "# Lets set the title for each plots\n",
    "ax[0].set_title(\"Distribution of loan amount between 2007 till 2011 applied by borrowers\", fontsize=14)\n",
    "ax[1].set_title(\"Distribution of funded amount between 2007 till 2011 for borrowers\", fontsize=14)\n",
    "ax[2].set_title(\"Distribution of interest rate between 2007 till 2011 for borrowers\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. What amount of loan was given each year? How many loans were given each year?\n",
    "#### Objective: We want to find any patterns of increase in loan counts and amounts between 2007 and 2011\n",
    "\n",
    "#### Observation: From the bar chart, the mean amount of loan gradually increased from 8KUSD to 12KUSD from 2007 to 2011. Indicates slight growth in business. From the line plot, we see that the number of loans exponentially increased in the same years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets plot a bar graph to see the average loan amount vs for each Year\n",
    "plt.figure(figsize=(13,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot('issue_year', 'funded_amnt_inv', data=df)\n",
    "plt.title('Average loan issued by year', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Average loan', fontsize=14)\n",
    "\n",
    "#Lets plot a line chart to see the number of loans for each year\n",
    "plt.subplot(1,2,2)\n",
    "g = df.groupby('issue_year')['funded_amnt_inv'].count()\n",
    "g.plot.line(x_compat=True)\n",
    "#plt.xticks(np.arange(min(g.index), max(g.index)+1, 1.0))\n",
    "plt.title('Number of loans issued between 2007 and 2011', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of loans', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. What percent of loans are fully paid, current and charged-off?\n",
    "\n",
    "#### Lets see the number of Bad loans in dataset to find out the percentage of risky loans\n",
    "- **Objective:**  To Check the total and percenatge of loan status from 2007 to 2011.\n",
    "- **Observation:** The pie-chart is for the entire period from 2007 to 2011. 83% of loans are fully paid, and 2.9% are currently running and about 14.2% are charged off. If we break it year-wise, the loans are current only in the last year. Maximum charge-off happened in 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the status of the loans given by Lending club\n",
    "df[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Pie chart for loan share by status across all the years\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Plotting Pie chart\n",
    "plt.suptitle('Loan share by loan status', fontsize=20)\n",
    "palette = [\"#0E720F\",\"#E01E1B\", \"#3791D7\"]\n",
    "df[\"loan_status\"].value_counts().plot.pie(ax=ax[0], colors = palette, \\\n",
    "                                          shadow=True,  fontsize=20, startangle=70, autopct='%1.1f%%')\n",
    "ax[0].set(title = \"Loan share from 2007 till 2011\")\n",
    "\n",
    "#Plotting Bar Chart to depict loan share by status for each year\n",
    "sns.barplot(x=\"issue_year\", y=\"funded_amnt_inv\", hue=\"loan_status\", \\\n",
    "            data=df, palette=palette, estimator=lambda x: len(x) / len(df) * 100)\n",
    "ax[1].set(ylabel=\"(Number of loans)\")\n",
    "ax[1].set(xlabel=\"(Year)\")\n",
    "ax[1].set(title=\"Loan share by loan status for each year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Are we going to do analysis for the entire population or filtering out? \n",
    "- We will remove all the current loan records as its of no value add to the analysis. After filtering out current loans, another way is to pick top 3 - 4 loans in each category, say top 4 months, 4 states and 4 reasons. We have analysed data for entire dataset and with topN approach. \n",
    "\n",
    "- In this Section (B) we will look at the entire dataframe as a whole and look at the paid-off and charged-off loan status values. The problem is to analyze charged-off loans which we will specifically address in Section (C). Yes, in Section (C), we will look at only charged-off loans with TopN criteria, to see rank ordering and patterns specific to charged-off loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE CURRENT loans\n",
    "currentFltr = ~df['loan_status'].isin([\"current\"])\n",
    "df = df.loc[currentFltr, :]\n",
    "\n",
    "#For ease of processing, convert \"fully paid\" as 0 and \"charged off\" as 1\n",
    "#We could use this for correlation\n",
    "df['loan_status_n'] = df['loan_status'].apply(lambda x: 0 if x == 'fully paid' else 1)\n",
    "\n",
    "df.head()\n",
    "print (df['loan_status'].value_counts())\n",
    "print (df['loan_status_n'].value_counts())\n",
    "\n",
    "#Box plot the annual_income to get the quantile values to bin the income\n",
    "plt.figure(figsize=(20,4))\n",
    "sns.boxplot( x=df[\"annual_inc\"] )\n",
    "plt.xlabel('Annual Income (in 1000 Dollars)')\n",
    "plt.title('Box plot of the anual income ')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Categorize the income based on the quantiles\n",
    "print(df['annual_inc'].describe())\n",
    "# we will use the 25, 50 and 75 quantiles to seggregate the income\n",
    "# x < 40000 --> 0\n",
    "# 40000 <= x < 50000 --> 1\n",
    "# 50000 <= x < 58000 --> 2\n",
    "# 58000 <= x < 70000 --> 3\n",
    "# 70000 <= x < 85000 --> 4\n",
    "# 85000 <= x --> 5\n",
    "def categorizeIncome(x):\n",
    "    if x < 40000:\n",
    "        return \"0, a_Less than 40K\"\n",
    "    elif 40000 <= x < 50000:\n",
    "        return \"1, b_40K to 50K\"\n",
    "    elif 50000 <= x < 58000:\n",
    "        return \"2, c_50K to 58K\"\n",
    "    elif 58000 <= x < 70000:\n",
    "        return \"3, d_58K to 70K\"\n",
    "    elif 70000 <= x < 85000:\n",
    "        return \"4, e_70K to 85K\"\n",
    "    else:\n",
    "        return \"5, f_Above 85K\"\n",
    "\n",
    "print(len(df['annual_inc']))\n",
    "df['inc_cat'] = df['annual_inc'].apply(categorizeIncome)\n",
    "df['inc_cat'].value_counts()\n",
    "\n",
    "#Get the 2 values, one for ease of processing, other for display ordering\n",
    "df[['income_category_n','income_category']] = df.inc_cat.str.split(\",\", expand=True)\n",
    "df['income_category'].value_counts()\n",
    "\n",
    "# Lets check the status of the loans given by Lending club\n",
    "#Create some filters \n",
    "paidOff = df['loan_status'] == 'fully paid'\n",
    "chargedOff = df['loan_status'] == 'charged off'\n",
    "\n",
    "dfPaidOff = df.loc[paidOff]\n",
    "dfChargedOff = df.loc[chargedOff]\n",
    "\n",
    "print (dfPaidOff['loan_status'].size)\n",
    "print (dfChargedOff['loan_status'].size)\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. What does grade mean? Does it have any relationship to loan amount?\n",
    "\n",
    "- **Objective:** What do grades mean? Does defaulting happen based on these?\n",
    "- **Observation:** The 3 plots below show that loan grades E, F and G have higher median amounts and are charged higher interest rates as they are high value and risky. The defaulting frequency is high in A, B, C and D grades.\n",
    "- **Conclusion:** When LC issues a high loan amount they have to look at other risk factors discussed further. Loan grades A, B, C and D needs to be analyzed further for risk as they have highest charged-off numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.pivot_table(data=df, values=['funded_amnt_inv'], index=['grade'], aggfunc=np.median)\n",
    "pt.plot(kind=\"bar\", figsize=[8,5])\n",
    "plt.title('Median loan amount by Grade', fontsize=16)\n",
    "plt.xlabel('Grade', fontsize=14)\n",
    "plt.ylabel('Median loan amount', fontsize=14)\n",
    "plt.xticks(rotation=360)\n",
    "plt.show()\n",
    "\n",
    "pt = pd.pivot_table(data=df, values=['funded_amnt_inv'], index=['grade'], columns=['loan_status'], aggfunc=\"count\")\n",
    "pt.plot(kind=\"bar\", figsize=[8,5])\n",
    "plt.title('Loan count by Grade', fontsize=16)\n",
    "plt.xlabel('Grade', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "plt.xticks(rotation=360)\n",
    "plt.show()\n",
    "\n",
    "df_grade= df.groupby(['grade','loan_status'])['int_rate'].median().reset_index().sort_values('int_rate', ascending =True)\n",
    "df_grade.head()\n",
    "# Lets see the relation of loan grade and the interest rate\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(y='int_rate', x='grade', data=df_grade)\n",
    "plt.ylabel('Interest rate', fontsize=14)\n",
    "plt.xlabel('Grade of loan', fontsize=14)\n",
    "plt.title('Loan grade vs Median interest rate', fontsize=16)\n",
    "plt.xticks(rotation=360)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Is interest rate impacting charged-off status? \n",
    "\n",
    "- **Objective:** Does interest rate and charged-off status have any relationship?\n",
    "- **Observation:** The boxplots show that when representative interest rate is 14% or more, they have higher chance of being charged-off. \n",
    "- **Conclusion:**  Most of the loans above interest rate 14% are at the risk of being charged-off. If interest rate is kept lower in the range of 8 - 11%, the risk of charging-off reduces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see the relationship between interest rate and loan status\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(y='int_rate', x='loan_status', data=df)\n",
    "plt.ylabel('Interest Rate in %', fontsize=16)\n",
    "plt.xlabel('Loan status', fontsize=16)\n",
    "plt.title('Interest rate vs Loan status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. How is the income spread? How is the loan amount spread? Purpose of loan? Is home ownership having any influence? Anything to do with bankruptcy counts? Will it help group states in to regions?\n",
    "\n",
    "#### Objective: Understand if any other factors have any influence of charged-off status.\n",
    "#### Observation:  Most of the loans are spread between 5K to 15K. Most of the borrowers have income between 4K to 83K.\n",
    "### Conclusion: Many conclusions from this step. \n",
    "- #### Looks like charged-off loans are from a slightly higher loan amount in the order of 12K and higher, but not a strong pattern indicating risk.\n",
    "- #### Debt consolidation, credit card, small business, other and home improvement reasons have highest charged off debts. Risky purposes.\n",
    "- #### Rental and Mortage home dwellers have higher charged-off status than owners. \n",
    "- #### The ratio of bankruptcy counts to none is higher for charged-off customers. If a person has gone banckrupt in the past, its most likely that he would default.\n",
    "- #### States grouped based on geography, indicate West region has taken more loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate loan_result as a percentage of amount recovered. This will be more than 100 for fully paid and \n",
    "#less than 100 for charged-off loans\n",
    "#df['loan_result']= (df['total_pymnt']-df['funded_amnt'])*100 / df['funded_amnt']\n",
    "\n",
    "#Loan to income Ratio\n",
    "df['loan_to_inc_ratio'] = df.funded_amnt_inv*100 / df.annual_inc\n",
    "\n",
    "# Annual income in thousand Dollars\n",
    "#df['annual_inc'] = df['annual_inc']/1000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "sns.boxplot( y=df[\"funded_amnt_inv\"] )\n",
    "plt.ylabel('Loan Amount $', fontsize=14)\n",
    "plt.title('Box plot of the loan amount issued', fontsize=16)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.boxplot( x=df[\"annual_inc\"] )\n",
    "plt.xlabel('Annual Income in $', fontsize=14)\n",
    "plt.title('Box plot of the anual income ', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "df['annual_inc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if there is any relationship between the loan amount funded and the loan status\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot( y=\"funded_amnt_inv\", x='loan_status' , data=df)\n",
    "plt.ylabel('Amount of the loan')\n",
    "plt.xlabel('Status of the Loan')\n",
    "plt.title( 'Loan amount vs Laon status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the details of loan purpose\n",
    "df.purpose.unique()\n",
    "\n",
    "# Lets draw a graph to show the loan status vs purpose\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(x='purpose', hue=\"loan_status\", data=df)\n",
    "plt.title(\"Purpose of loan vs loan status\", fontsize=16)\n",
    "plt.xlabel('Purpose', fontsize=14)\n",
    "plt.ylabel('Loan counts', fontsize=14)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='home_ownership',hue='loan_status', data=df)\n",
    "plt.ylabel('Loan counts')\n",
    "plt.title(\"Home ownership vs loan status\", fontsize=16)\n",
    "plt.xlabel(\"Home ownership\", fontsize=14)\n",
    "plt.ylabel(\"Loan counts\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.pivot_table(data=df, columns=['pub_rec_bankruptcies'], values=['funded_amnt_inv'], index=['loan_status'], aggfunc=\"count\")\n",
    "pt.plot(kind=\"bar\", figsize=[10,6])\n",
    "plt.title(\"Bankruptcy count across loan status\", fontsize = 16) \n",
    "plt.xlabel(\"Loan status\", fontsize=14)\n",
    "plt.ylabel(\"Loan counts\", fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a loan_group df to see the insights\n",
    "Loan_group = df.groupby(['issue_month','Region'], as_index=False).sum()\n",
    "#Scale down by 1000 Dollars\n",
    "Loan_group.funded_amnt_inv = Loan_group.funded_amnt_inv / 1000\n",
    "Loan_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the graph to see correlation\n",
    "df_dates = pd.DataFrame(data=Loan_group[['issue_month','Region','funded_amnt_inv']])\n",
    "by_issued_amount = df_dates.groupby(['issue_month', 'Region']).funded_amnt_inv.sum()\n",
    "by_issued_amount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the graph to see correlation\n",
    "#plt.style.use(\"grayscale\")\n",
    "cmap = plt.cm.Set3\n",
    "by_issued_amount.unstack().plot(stacked=False, colormap=cmap, grid=False, legend=True,figsize=(15,6))\n",
    "plt.ylabel('Total funded loan amount')\n",
    "plt.title('Loan issued by Region', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Will it help group states in to regions? Lets look at mean interest rates, employee length, debt-to-income ratio and annual income across the regions for anything abnormal.\n",
    "\n",
    "#### Objective: Understand if any pattern emerges across regions.\n",
    "### Observation:  \n",
    "\n",
    "- #### Average interest rate, employment length, DTI and Annual income across different regions for each month are showing some pattens but are NOT strong. We have to use States individually to see patterns. \n",
    "- #### Customers with lowest average annual income have taken loans in December.\n",
    "- #### Average employment length of Customers is lowest in January.\n",
    "- #### Across regions, Jan had lowest interet rate and Dec had highest.\n",
    "- #### Customers who took loans in December seem to have the highest DTI.\n",
    "- #### West, north-east, south-east have the highest default loans.\n",
    "- #### Small business, debt consolidation, credit card, major purchase seem to be the top reasons for charged-off loans with high loan/income ratio.\n",
    "- #### For mid-west region, the loan/income ratio is highest and in general this ratio is high for charged-off customers.\n",
    "- #### Income group <40K defaults the most. This is a risk item.\n",
    "- #### Though there are positive and negative correlations, these don't relate to charged-off status.\n",
    "- #### LC is already charging higher interest rates for higher salaried customers.\n",
    "- #### Debt/Income ratio is lower as income increases. 50-58K group has the highest and lowest in >85K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets draw the plot\n",
    "sns.set_style('whitegrid')\n",
    "by_int_rate = df.groupby(['issue_month', 'Region']).int_rate.mean()\n",
    "by_int_rate.unstack().plot(kind='bar', stacked=False, grid=True, legend=True,figsize=(12,6))\n",
    "plt.title('Average interest rate across different regions for each month', fontsize=16)\n",
    "plt.ylabel('Mean interest rate', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "by_emp_length = df.groupby(['issue_month', 'Region']).emp_length.mean()\n",
    "by_emp_length.unstack().plot(kind='bar', stacked=False, grid=True, legend=True,figsize=(12,6))\n",
    "plt.title('Average employment length across different regions for each month', fontsize=16)\n",
    "plt.ylabel('Mean interest rate', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "by_dti = df.groupby(['issue_month', 'Region']).dti.mean()\n",
    "by_dti.unstack().plot(kind='bar', stacked=False, grid=True, legend=True,figsize=(12,6))\n",
    "plt.title('Average (Debt to Income Ratio) DTI across different regions for each month', fontsize=16)\n",
    "plt.ylabel('Debt to income ratio', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "by_income = df.groupby(['issue_month', 'Region']).annual_inc.mean()\n",
    "by_income.unstack().plot(kind='bar', stacked=False, grid=True, legend=True,figsize=(12,6))\n",
    "plt.title('Average Annual Income across different regions for each month', fontsize=16)\n",
    "plt.ylabel('Average annual income', fontsize=14)\n",
    "plt.xlabel('Month', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the region wise loan status\n",
    "plt.figure(figsize=(12,5))\n",
    "g = df[df['loan_status'] == 'charged off'].groupby('Region')['loan_status'].count().reset_index()\n",
    "sns.barplot(x='Region', y='loan_status', data=g)\n",
    "plt.ylabel('Count of default loans', fontsize=14)\n",
    "plt.xlabel('Region', fontsize=14)\n",
    "plt.title('Number of charged-off loans across regions', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the relationship between loan to income ratio vs loan status for different purposes\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.barplot(x='loan_status', y='loan_to_inc_ratio', hue='purpose', data=df)\n",
    "plt.xlabel('Status of the loan issued', fontsize=\"16\")\n",
    "plt.ylabel('(Loan issued/Annual income)%', fontsize=\"16\")\n",
    "plt.title('Mean (Loan/Annual income)% spread across \\'loan purpose\\' for loan status ', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the relation between loan to income ratio vs loan status for different Region\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='loan_status',y='loan_to_inc_ratio',hue='Region',data=df)\n",
    "plt.xlabel('Status of the loan issued', fontsize=\"16\")\n",
    "plt.ylabel('(Loan issued/Annual income)%', fontsize=\"16\")\n",
    "plt.title('Mean (Loan/Annual income)% spread across Region for loan status ', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets analyze which income group defaults the most? Looks like income group <40K defaults the most.\n",
    "pt = pd.pivot_table(data=df, values=['funded_amnt_inv'], index=['loan_status'], \\\n",
    "                    columns = ['income_category'], aggfunc=\"count\")\n",
    "pt.plot(kind=\"bar\", figsize=[10,6])\n",
    "plt.title('Which income group defaults the most?', fontsize=16)\n",
    "plt.xlabel('Loan status', fontsize=14)\n",
    "plt.ylabel('Loan counts', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets analyze which income group defaults the most? Looks like income group <40K defaults the most.\n",
    "pt = pd.pivot_table(data=df, values=['dti'], index=['income_category'], \\\n",
    "                     aggfunc=np.median)\n",
    "pt.plot(kind=\"bar\", figsize=[10,5])\n",
    "plt.title('Which income group has the highest (Median) DTI?', fontsize=16)\n",
    "plt.xlabel('Income group', fontsize=14)\n",
    "plt.ylabel('Median DTI', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets analyze which income group defaults the most? Looks like income group <40K defaults the most.\n",
    "pt = pd.pivot_table(data=df, values=['int_rate'], index=['income_category'], \\\n",
    "                     aggfunc=np.mean)\n",
    "pt.plot(kind=\"bar\", figsize=[10,5])\n",
    "plt.title('Which income group has the highest (Median) DTI?', fontsize=16)\n",
    "plt.xlabel('Income group', fontsize=14)\n",
    "plt.ylabel('Median DTI', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "cont_var= ['loan_status_n', 'funded_amnt_inv', 'int_rate', 'term', 'emp_length', 'annual_inc', 'dti', \\\n",
    "          'pub_rec_bankruptcies', 'loan_to_inc_ratio', 'income_category']   \n",
    "corr = df[cont_var].corr()\n",
    "sns.heatmap(corr, annot=True, center=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of income category vs different variables\n",
    "fig, ((ax1, ax2), (ax3, ax4))= plt.subplots(nrows=2, ncols=2, figsize=(20,10))\n",
    "\n",
    "# Plot of income category vs loan amount\n",
    "sns.violinplot(x=\"income_category\", y=\"funded_amnt_inv\", data=df, palette=\"Set2\", ax=ax1 )\n",
    "plt.xticks(rotation=90)\n",
    "# Plot of income category vs loan status\n",
    "sns.violinplot(x=\"income_category\", y=\"loan_status_n\", data=df, palette=\"Set2\", ax=ax2)\n",
    "plt.xticks(rotation=90)\n",
    "# Plot of income category vs interest rate\n",
    "sns.boxplot(x=\"income_category\", y=\"int_rate\", data=df, palette=\"Set2\", ax=ax3)\n",
    "plt.xticks(rotation=90)\n",
    "# Plot of income category vs loan/income ratio\n",
    "sns.boxplot(x=\"income_category\", y=\"loan_to_inc_ratio\", data=df, palette=\"Set2\", ax=ax4)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Plot how many loans were issued by grade\n",
    "f, ((ax1, ax2)) = plt.subplots(1, 2)\n",
    "cmap = plt.cm.coolwarm\n",
    "\n",
    "by_credit_score = df.groupby(['issue_month', 'grade']).funded_amnt_inv.mean()\n",
    "by_credit_score.unstack().plot(legend=False, ax=ax1, figsize=(14, 5), colormap=cmap)\n",
    "ax1.set_title('Loans issued by Grade', fontsize=14)\n",
    "    \n",
    "    \n",
    "by_inc = df.groupby(['issue_month', 'grade']).int_rate.mean()\n",
    "by_inc.unstack().plot(ax=ax2, figsize=(14, 5), colormap=cmap)\n",
    "ax2.set_title('Interest Rates by Grade', fontsize=14)\n",
    "\n",
    "ax2.legend(bbox_to_anchor=(-1.0, -0.3, 1.7, 0.1), loc=5, prop={'size':12}, ncol=7, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section (C) Risk analysis with TopN criteria for charged-off loans.\n",
    "### Now that we have completed analysis and concluded on the entire dataset, we will move on to charged-off loans between 2007 and 2011. If we identify a pattern across the TopN criteria, we will be able to solve for the entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHistogram(desc, series):\n",
    "    print(desc.upper())\n",
    "    print(series.describe())\n",
    "    plt.hist(series)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Does charged-off loans get influenced by term and interest rates?\n",
    "\n",
    "#### Objective: Identify the influence of terms and interest rates.\n",
    "#### Observation:  For those with 36 months term, approx 1900 of them dropped out when interest rate was 11 - 15 percent. From 60 months term, about 900 of them dropped out when interest rate was 15 - 17 percent. Observe that the defaulter count is low for 36 months as interest rate increases. \n",
    "### Conclusion: For either terms, if the interest rate is reduced, defaulting behavior can be reduced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfChargedOff is the dataframe with charged-off loans between 2007 and 2011\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(dfChargedOff['term'])\n",
    "plt.title('Loans per term(36 and 60 months)', fontsize=16)\n",
    "plt.xlabel('Months', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(dfChargedOff['int_rate'])\n",
    "plt.title('Frequency of interest rates', fontsize=16)\n",
    "plt.xlabel('Interest rate', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "\n",
    "_36monthChargedOff = dfChargedOff[dfChargedOff['term'] == 36]\n",
    "_60monthChargedOff = dfChargedOff[dfChargedOff['term'] == 60]\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(_36monthChargedOff['int_rate'])\n",
    "plt.title('Frequency of interest rate with 36month term', fontsize=16)\n",
    "plt.xlabel('Interest rate', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(_60monthChargedOff['int_rate'])\n",
    "plt.title('Frequency of interest rate with 60month term', fontsize=16)\n",
    "plt.xlabel('Interest rate', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.pivot_table(data=dfChargedOff, values=['funded_amnt_inv'], index=['term'], columns = ['int_rate'], aggfunc='count')\n",
    "pt.plot(kind=\"bar\", figsize=[10,6])\n",
    "plt.title('Frequency of interest rates', fontsize=16)\n",
    "plt.xlabel('Terms', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. We want to find the reason for charged-off loans. What are the top 4 - states, purposes and months of the year, for which charged-off numbers are high?\n",
    "\n",
    "#### Objective: Identify top 4 states, purposes and months where charge-off is high.\n",
    "#### Observation:  The top 4 states are 'CA', 'FL', 'NY', 'TX'. Top 4 purpose for which loan is issued are 'debt_consolidation', 'other', 'credit_card', 'small_business'. Top 4 months when loan issued are defaulted - 'DEC', 'NOV', 'OCT', 'SEP'. Note that these States are responsible for high default rate conciding with the corresponding Region in the previous Section.\n",
    "### Conclusion: In the above mentioned 4 months (specifically Nov and Dec), customers ask for loan with debt consolidation as a reason in the 4 (especially California) states and default maximum. Towards the end of the year, as celebration begins, customers prepare to take the loan and default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar plotting loan counts across issue month, states and purpose was too distracting.\n",
    "#We will restrict it to TOP 4 months, states and purpose\n",
    "print(\"***********Top 4 months, states and purpose************\")\n",
    "print(\"*******************************************************\")\n",
    "print(dfChargedOff['issue_month'].value_counts()[:4])\n",
    "print(dfChargedOff['purpose'].value_counts()[:4])\n",
    "print(dfChargedOff['addr_state'].value_counts()[:4])\n",
    "\n",
    "top4MONTHS_Filter = dfChargedOff['issue_month'].isin(['DEC', 'NOV', 'OCT', 'SEP'])\n",
    "top4PURPOSE_Filter = dfChargedOff['purpose'].isin(['debt_consolidation', 'other', 'credit_card', 'small_business'])\n",
    "top4STATE_Filter = dfChargedOff['addr_state'].isin(['CA', 'FL', 'NY', 'TX'])\n",
    "\n",
    "top4MONTHS_dfChargedOff = dfChargedOff[top4MONTHS_Filter]\n",
    "top4STATES_dfChargedOff = dfChargedOff[top4STATE_Filter]\n",
    "top4PURPOSE_dfChargedOff = dfChargedOff[top4PURPOSE_Filter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(19, 6))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(top4MONTHS_dfChargedOff['issue_month'])\n",
    "plt.title('Loans for top 4 months', fontsize=16)\n",
    "plt.xlabel('Months', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(top4PURPOSE_dfChargedOff['purpose'])\n",
    "plt.title('Loans for top 4 purposes', fontsize=16)\n",
    "plt.xlabel('Purpose of loan', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(top4STATES_dfChargedOff['addr_state'])\n",
    "plt.title('Loans for top 4 states', fontsize=16)\n",
    "plt.xlabel('States', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP4_dfChargedOff = dfChargedOff[top4MONTHS_Filter & top4PURPOSE_Filter & top4STATE_Filter]\n",
    "TOP4_dfChargedOff.head()\n",
    "\n",
    "pt = pd.pivot_table(data=TOP4_dfChargedOff, index=['addr_state', 'issue_month'], columns=['purpose'], \\\n",
    "                    values=['funded_amnt_inv'], aggfunc='count')\n",
    "pt.plot(kind=\"bar\", figsize=[15,7], fontsize=10)\n",
    "plt.title(\"Charged-off loan count across TOP 4 months, purpose and states\", fontsize = 16, fontweight ='bold') \n",
    "plt.xlabel('State, Month', fontsize=14)\n",
    "plt.ylabel('Loan count', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Within the top 4, does grade have any impact to default?\n",
    "\n",
    "#### Objective: Identify if grade has an impact for top 4 states, months, reasons. \n",
    "#### Observation: Loan counts for top 4 months split across grade yields the same result as Step 2. Customers with grade A, B and C loans default the most. Customes whose annual income is less than 40K default the most.\n",
    "### Conclusion: Giving loan to a customer under the Top 4 criteria with income less than 40K and grade A, B and C is risky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have used the 25, 50 and 75 quantiles to seggregate the income\n",
    "\n",
    "#Lets check if credit history has an impact on top4 (month, state, purpose)\n",
    "pt = pd.pivot_table(data=TOP4_dfChargedOff, index=['income_category'], columns=['grade'], \\\n",
    "                    values=['funded_amnt_inv'], aggfunc='count')\n",
    "pt.plot(kind=\"bar\", figsize=[10,7])\n",
    "plt.xlabel(\"Income range\", fontsize=14)\n",
    "plt.ylabel(\"Loan counts\", fontsize=14)\n",
    "plt.title(\"Charged-off loan count (for Top4 criteria) across Grades for 5 income ranges\", fontsize = 16, fontweight ='bold') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some filters for NOV-DEC, Debt consolidation and California and\n",
    "#create the new dataframe.\n",
    "NOVDEC_Filter = dfChargedOff['issue_month'].isin(['DEC', 'NOV'])\n",
    "DEBT_CONS_Filter = dfChargedOff['purpose'].isin(['debt_consolidation'])\n",
    "CALIFORNIA_Filter = dfChargedOff['addr_state'].isin(['CA'])\n",
    "\n",
    "_2Mn_dbt_CA_dfChargedOff = dfChargedOff[NOVDEC_Filter & DEBT_CONS_Filter & CALIFORNIA_Filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Within the top 4, does employment length have any influence to default?\n",
    "\n",
    "#### Objective: Identify if current employment length has an impact for top 4 states, months, reasons. \n",
    "#### Observation:  Loan counts for top 4 months split across emp_length yields that employees with less than 2 years of employment length default the most. As the number of years of employment with the current employer increases, the tendency to default reduces steeply.\n",
    "### Conclusion: Lending money to customers fitting top 4 criteria with employment length less than 2 years is risky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove employment greater than 10 years as it gives a false negative.\n",
    "EMPLEN_Filter = ~TOP4_dfChargedOff['emp_length'].isin(['10'])\n",
    "emp_LT10_TOP4_dfChargedOff = TOP4_dfChargedOff[EMPLEN_Filter]\n",
    "\n",
    "pt = pd.pivot_table(data=emp_LT10_TOP4_dfChargedOff, index=['issue_month'], columns=['emp_length'], \\\n",
    "                    values=['funded_amnt_inv'], aggfunc='count')\n",
    "pt.plot(kind=\"bar\", figsize=[10,6])\n",
    "plt.title(\"Charged-off loan count in top 4 months, by employment length\", fontsize = 16, fontweight ='bold') \n",
    "plt.xlabel(\"Loan issue month\", fontsize=14)\n",
    "plt.ylabel(\"Loan counts\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Now that we know in last quater, especially December, customers take debt consolidation loan and default. Does home ownership affect defaulting nature?\n",
    "\n",
    "#### Objective - Analyze if home ownership has any influence on defaulting nature for top4 criteria customers.\n",
    "#### Observation - Yes, those who rent default significantly higher than mortagers and mortgagers default higher than home owners. \n",
    "### Conclusion - If a customer fitting top 4 criteria in rental home, applies for loan with purpose debt consolidation in the last 4 months, its risky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.pivot_table(data=TOP4_dfChargedOff, index=['issue_month'], columns=['home_ownership'], \\\n",
    "                    values=['funded_amnt_inv'], aggfunc='count')\n",
    "pt.plot(kind=\"bar\", figsize=[12,6])\n",
    "plt.title(\"Charged-off loan count in top 4 criteria, by home ownership\", fontsize = 16, fontweight ='bold')\n",
    "plt.xlabel(\"Loan issue month\", fontsize=14)\n",
    "plt.ylabel(\"Loan counts\", fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Does verification status impact the top 4 criteria defaulters?\n",
    "\n",
    "#### Objective - Analyze if verification status has any impact on default tendency.\n",
    "#### Observation - Loans that are source verified have lesser defaults. Its 1/3rd of total defaults.\n",
    "### Conclusion - When loans are issued without source verification, they are very risky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.pivot_table(data=TOP4_dfChargedOff, index=['issue_month'], columns=['verification_status'], \\\n",
    "                    values=['funded_amnt_inv'], aggfunc='count')\n",
    "pt.plot(kind=\"bar\", figsize=[12,6])\n",
    "plt.title(\"Charged-off loan counts by verification status across the top4 months\", fontsize = 16, fontweight ='bold')\n",
    "plt.xlabel(\"Loan issue month\", fontsize=14)\n",
    "plt.ylabel(\"Loan counts\", fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. What is the impact of DTI on defaulting nature?\n",
    "#### Objective - In the months Nov, Dec, for the state of California, for those customers who take loan with reason as debt consolidation, we want to know the DTI relationship. \n",
    "#### Observation - For rental defaulters, the Median DTI is high and close to home owners. DTI is higer than mortagers, its risky to lend money to rental owners. In many plots earliers, we saw that rental is risky. This reinforces the theory.\n",
    "\n",
    "### Conclusion - Risky to give loans to rental customers with higher DTI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_EMPLEN_Filter = ~_2Mn_dbt_CA_dfChargedOff['emp_length'].isin(['10'])\n",
    "dtiAnalysis_df = _2Mn_dbt_CA_dfChargedOff[l_EMPLEN_Filter]\n",
    "\n",
    "pt = pd.pivot_table(data=dtiAnalysis_df, index=['home_ownership'], values=['dti'], aggfunc=np.median)\n",
    "pt.plot(kind=\"bar\", figsize=[8,5])\n",
    "plt.title(\"Median of DTI(Debt-to-income ratio) \\nacross home-ownership type\", fontsize = 16, fontweight ='bold')\n",
    "plt.xlabel('Home ownership', fontsize=14)\n",
    "plt.ylabel('DTI', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "#### Consider LC tightly controls loan applications with the following overlapping conditions:\n",
    "- Customers with less than 2 years of experience\n",
    "- Loan grade is A, B or C\n",
    "- Purpose of loan is debt consolidation, other, credit card, small business\n",
    "- Rental customers\n",
    "- Income is less than 58K\n",
    "#### LC could have converted 2916 charged-off loans worth USD20,038,752 to good loans (of the total 5627 charged-off loans worth USD61,131,728) which is 32%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how much LC could have done better with our analysis\n",
    "#Build the worst case high probability defaulter case\n",
    "fltr1 = df['emp_length'].isin(['0', '1', '2'])\n",
    "fltr2 = df['grade'].isin(['A','B','C'])\n",
    "fltr3 = df['purpose'].isin(['debt_consolidation', 'other', 'credit_card', 'small_business'])\n",
    "fltr4 = df['home_ownership'].isin(['RENT'])\n",
    "fltr5 = df['income_category_n'].isin(['0','1', '2'])\n",
    "\n",
    "highProbDf = df[fltr1 & fltr2 & fltr3 & fltr4 & fltr5]\n",
    "\n",
    "print(\"High probability defaulter count - \", len(highProbDf))\n",
    "print(\"Charged-off loans count - \", len(dfChargedOff))\n",
    "print(\"Fully paid and charged-off loans number - \", len(df))\n",
    "\n",
    "highProbDf.describe()\n",
    "\n",
    "highProbDfVal = 2916 * 6872.00 #Count x Mean\n",
    "dfChargedOffDfVal = 5627 * 10864.00 #Count x Mean\n",
    "\n",
    "print (\"High probabilty defaulter loan value - \", highProbDfVal, \\\n",
    "       \"Defaulter loan value - \", dfChargedOffDfVal, \\\n",
    "       \"High Probability defaulter loan value / Defaulter loan value - \", (highProbDfVal/dfChargedOffDfVal)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF ASSIGNMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
