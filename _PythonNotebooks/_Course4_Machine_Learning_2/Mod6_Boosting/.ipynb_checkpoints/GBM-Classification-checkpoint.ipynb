{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "adfbe30e-7ebb-0f88-d917-d9a8f97c638e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f9dfd4eb19b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Import and suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5af03c82-cb84-d943-f82c-fc0a15d46b48"
   },
   "source": [
    "# 1. Exploratory Data Analysis\n",
    "\n",
    "Let us load in the dataset via the trusty Pandas package into a dataframe object which we call **attrition** and have a quick look at the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e035b071-50f8-43ca-9611-fc47272bb05e"
   },
   "outputs": [],
   "source": [
    "attrition = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57e2bf45-5920-af03-50c1-b5bba334eb11"
   },
   "outputs": [],
   "source": [
    "# Looking for NaN\n",
    "attrition.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition.Age.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c5dc2ed-7608-4d84-c4f6-c591a3be7570"
   },
   "source": [
    "### Correlation of Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "112cef65-78b8-7790-e705-b173beea6986"
   },
   "source": [
    "#  Feature Engineering & Categorical Encoding\n",
    "\n",
    "Task of Feature engineering and numerically encoding the categorical values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "937385c7-7b7f-f6d0-d974-0527a7118e98"
   },
   "outputs": [],
   "source": [
    "# Empty list to store columns with categorical data\n",
    "categorical = []\n",
    "for col, value in attrition.iteritems():\n",
    "    if value.dtype == 'object':\n",
    "        categorical.append(col)\n",
    "\n",
    "# Store the numerical columns in a list numerical\n",
    "numerical = attrition.columns.difference(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ec5cd49-f8b3-e36b-75dd-ac95fe0373ac"
   },
   "outputs": [],
   "source": [
    "# Store the categorical data in a dataframe called attrition_cat\n",
    "attrition_cat = attrition[categorical]\n",
    "attrition_cat = attrition_cat.drop(['Attrition'], axis=1) # Dropping the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c3c0c95-3725-80dd-0a73-5c840451a438"
   },
   "source": [
    "Applying the **get_dummies** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can you convert categorial or string or object data into Numerical Format ?\n",
    "\n",
    "# Process of converting your cat data into numerical format - Encoding process \n",
    "\n",
    "# Encoding (15 More )\n",
    "\n",
    "# Label Encoding \n",
    "\n",
    "# One Hot Encoding ( OHE)\n",
    "\n",
    "# Cat_A \n",
    "\n",
    "# Male\n",
    "#Female \n",
    "#Male\n",
    "#Female\n",
    "# Prefer_not_to_say\n",
    "# Male \n",
    "\n",
    "# OHE \n",
    "\n",
    "           # Cat_A_Male    #Cat_A_Female   #Cat_A_Prefer_not_to_say\n",
    "#1# Male      1             0                0 \n",
    "#2#Female     0             1                0\n",
    "#3#Male       1             0                0\n",
    "#4#Female     0             1                0\n",
    "#5# Prefer_not_to_say 0     0                1\n",
    "#6# Male \n",
    "\n",
    "\n",
    "\n",
    "# Label Encoding \n",
    "\n",
    "# Cat_A \n",
    "\n",
    "# Male   2       \n",
    "#Female 1\n",
    "#Male 2\n",
    "#Female 1\n",
    "# Prefer_not_to_say 3\n",
    "# Male 2\n",
    "\n",
    "# Target Encoding \n",
    "# Mean Encoding \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter your object datatypes \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "le.transform([\"tokyo\", \"tokyo\", \"paris\",\"amsterdam\"])\n",
    "\n",
    "# list(le.classes_)\n",
    "\n",
    "\n",
    "#0 ,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ea5b0d8-1f13-e56b-72cf-bcbe7dd6fad2"
   },
   "outputs": [],
   "source": [
    "attrition_cat = pd.get_dummies(attrition_cat)\n",
    "attrition_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de8b3a57-6aba-eae7-2be3-dbe0ae761d6a"
   },
   "outputs": [],
   "source": [
    "# Store the numerical features to a dataframe attrition_num\n",
    "attrition_num = attrition[numerical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9de23a93-10b6-33b8-eea8-0cf44c6e5e08"
   },
   "source": [
    "let's concat numerical and caterogial dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b90b69ba-f19d-0707-7c2c-183b8d01130f"
   },
   "outputs": [],
   "source": [
    "# Concat the two dataframes together columnwise\n",
    "attrition_final = pd.concat([attrition_num, attrition_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a295568-fab4-b79a-bc0d-be32ad032b3e"
   },
   "source": [
    "**Target variable**\n",
    "\n",
    "The target in this case is given by the column **Attrition** which contains categorical variables therefore requires numerical encoding. We numerically encode it by creating a dictionary with the mapping given as 1 : Yes and 0 : No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfa5e82f-2dd3-1bee-5b2b-367468be7040"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary for the target mapping\n",
    "target_map = {'Yes':1, 'No':0}\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "target = attrition[\"Attrition\"].apply(lambda x: target_map[x])\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5564e6e1-83ed-75de-2540-0d037e31291b"
   },
   "source": [
    "\n",
    "**Splitting Data into Train and Test sets**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c197f8ee-76b0-7137-f001-83f969637521"
   },
   "outputs": [],
   "source": [
    "# Split data into train and test sets as well as for validation and testing\n",
    "train, test, target_train, target_test = train_test_split(attrition_final, target, train_size= 0.75,random_state=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implementing Machine Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "610cfa87-0b9d-4671-cd51-c99ef9c9151d"
   },
   "source": [
    "## GBM Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.n_estimators - No of Trees in the Model\n",
    "\n",
    "### 2.max_features - The number of features to consider while searching for a best split.Thumb Rule to have Square root of no of Columns\n",
    "\n",
    "### 3.max_depth - Maximum Depth of Tree and can be used to control overfiting \n",
    "\n",
    "### 4.min_samples_leaf - Minimum samples (or observations) required in a terminal node or leaf.In general we need to have lower values  for it for Imbalanced problems\n",
    "\n",
    "### 5.subsample- The fraction of samples to be used for fitting the individual base learners\n",
    "\n",
    "### 6.learning_rate - Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=100) # default \n",
    "gb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed6a837e-2864-291c-be8d-3c8e9ed900b7"
   },
   "outputs": [],
   "source": [
    "# Fit the model to our train and target\n",
    "gb.fit(train, target_train)\n",
    "# Get our predictions\n",
    "gb_predictions = gb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_predictions_prob = gb.predict_proba(test)\n",
    "gb_predictions_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Parameters\n",
    "# gb_params ={\n",
    "#     'n_estimators': 500,   # no of Trees \n",
    "#     'learning_rate' : 0.2,\n",
    "#     'max_depth': 11,\n",
    "#     'min_samples_leaf': 2,\n",
    "#     'subsample': 1,\n",
    "#     'max_features' : 'sqrt',\n",
    "#     'random_state' : 100,\n",
    "#     'verbose': 0\n",
    "# }\n",
    "\n",
    "#gb = GradientBoostingClassifier(**gb_params) # After Doing HPT , we can pass the paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40c37011-76df-fcc7-9cd0-e689374a8d1a"
   },
   "outputs": [],
   "source": [
    "accuracy_score(target_test, gb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21cc0476-b03e-731f-97b4-89d81977c3a7"
   },
   "source": [
    "### Feature Importance Gradient Boosting Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "082ca641-ffd2-fc3b-a7b6-9418b08767d9"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = gb.feature_importances_,\n",
    "    x = attrition_final.columns.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1.3,\n",
    "        size = 12,\n",
    "        color = gb.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = attrition_final.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'GBM Model Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 5,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
