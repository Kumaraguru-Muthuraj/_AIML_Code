{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this for sentiment analysis with Logistic Regression and Naive Bayes\n",
    "- http://localhost:8888/notebooks/_PythonNotebooks/_Course8_Deployment_Capstone/1_IMPORTANT_Capstone-Project-master/Capstone-Project-master/Capstone_Project_Sentiment_Analysis.ipynb\n",
    "- http://localhost:8888/notebooks/_PythonNotebooks/_Course8_Deployment_Capstone/1_IMPORTANT_Capstone-Project-master/Capstone-Project-master/Capstone_Project_KNN_RecommenderSystem.ipynb\n",
    "- http://localhost:8888/notebooks/_PythonNotebooks/_Course8_Deployment_Capstone/2_Amazon-Product-Recommender-System-master/Naive%20Bayes/Amazon%20reviews_Naive%20Bayes.ipynb\n",
    "- http://localhost:8888/notebooks/_PythonNotebooks/_Course8_Deployment_Capstone/2_Amazon-Product-Recommender-System-master/Recommender%20System/Recommender%20System.ipynb\n",
    "\n",
    "Removing Contractions - https://medium.com/analytics-vidhya/sentiment-analysis-on-amazon-reviews-using-tf-idf-approach-c5ab4c36e7a1\n",
    "\n",
    "\n",
    "http://localhost:8888/notebooks/_PythonNotebooks/_Course8_Deployment_Capstone/Recommendation%2BSystem%2BNotebook_WIP.ipynb\n",
    "http://localhost:8888/notebooks/_PythonNotebooks/_Course8_Deployment_Capstone/Recommendation%2BSystem%2BNotebook.ipynb\n",
    "\n",
    "http://localhost:8888/notebooks/_PythonNotebooks/_Course8_Deployment_Capstone/Akash_collaborative_user_base..ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'brand', 'categories', 'manufacturer', 'name', 'reviews_date',\n",
      "       'reviews_didPurchase', 'reviews_doRecommend', 'reviews_rating',\n",
      "       'reviews_text', 'reviews_title', 'reviews_userCity',\n",
      "       'reviews_userProvince', 'reviews_username', 'user_sentiment'],\n",
      "      dtype='object')\n",
      "(30000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the review text to words\n",
    "reg = re.compile('[^a-z]+')\n",
    "def tokenizeReview(text):\n",
    "    text = text.lower()\n",
    "    text = reg.sub(' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_tokenized'] = df['reviews_text'].apply(tokenizeReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['reviews_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i love this album it s very good more to the h...\n",
       "1    good flavor this review was collected as part ...\n",
       "2                                          good flavor\n",
       "3    i read through the reviews on here before look...\n",
       "4    my husband bought this gel for us the gel caus...\n",
       "Name: reviews_tokenized, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_tokenized'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    26632\n",
       "Negative     3367\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti(txt):\n",
    "    if str(txt).lower() == 'positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X = df['reviews_tokenized']\n",
    "y = df['user_sentiment'].apply(senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "29995    1\n",
       "29996    1\n",
       "29997    1\n",
       "29998    1\n",
       "29999    1\n",
       "Name: user_sentiment, Length: 30000, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 1000\n",
      "accuracy of the model:  0.9221666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.38      0.52       660\n",
      "           1       0.93      0.99      0.96      5340\n",
      "\n",
      "    accuracy                           0.92      6000\n",
      "   macro avg       0.87      0.69      0.74      6000\n",
      "weighted avg       0.92      0.92      0.91      6000\n",
      "\n",
      "\n",
      "Top 10 positive features (variables)\n",
      "      Word  Coefficient\n",
      "     great    13.299884\n",
      "      love    11.054383\n",
      "      best     8.156580\n",
      "      good     7.800511\n",
      "      easy     7.735733\n",
      "     clean     7.719841\n",
      "    better     5.808192\n",
      "     loved     5.688351\n",
      "      nice     5.268984\n",
      " excellent     5.121848\n",
      "   awesome     4.898837\n",
      "   perfect     4.861898\n",
      "  favorite     4.555234\n",
      "   enjoyed     4.373794\n",
      "   amazing     4.364436\n",
      "      free     3.939587\n",
      " wonderful     3.916948\n",
      "    really     3.575024\n",
      "     handy     3.529437\n",
      "     happy     3.373818\n",
      "\n",
      "Top 10 negative features (variables)\n",
      "          Word  Coefficient\n",
      "          base    -1.578752\n",
      " unfortunately    -1.630364\n",
      " disappointing    -1.851355\n",
      "           sad    -2.030757\n",
      "       chicken    -2.034986\n",
      "         crazy    -2.535949\n",
      "      resident    -2.611503\n",
      "          hate    -3.260024\n",
      "         wrong    -3.262962\n",
      "          cold    -3.268827\n",
      "         worst    -3.655030\n",
      "           bad    -3.925396\n",
      "          evil    -4.017543\n",
      "         dirty    -4.033550\n",
      "         awful    -4.161197\n",
      "         nasty    -4.319006\n",
      "      horrible    -4.578781\n",
      "  disappointed    -4.636527\n",
      "          sick    -4.697851\n",
      "      terrible    -4.804326\n"
     ]
    }
   ],
   "source": [
    "def model_fit(X, y, feature_model,ml_model,coef_show=1):\n",
    "    \n",
    "    X_features = feature_model.fit_transform(X)\n",
    "    print('# features: {}'.format(X_features.shape[1]))\n",
    "    \n",
    "#    tempX = feature_model.transform(['this is an awful product', 'i am satisfied with this. will come back again'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size = 0.2, random_state=43)\n",
    "    clf = ml_model.fit(X_train, y_train)\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    model_performance = classification_report(y_test, clf_pred)\n",
    "    print ('accuracy of the model: ', accuracy)\n",
    "    print('')\n",
    "    print(model_performance)\n",
    "\n",
    "#    print(X_train)\n",
    "#    print(\"---\")\n",
    "#    print(X_test)\n",
    "#    print(\"---\")\n",
    "#    print(dir(ml_model))\n",
    "    \n",
    "#    tempPred = ml_model.predict(tempX)\n",
    "#    print('---Prediction----')\n",
    "#    print(tempPred)\n",
    "    \n",
    "#    print(vars(X_test))\n",
    "#    print(\"indices - \", len(X_test.indices))\n",
    "#    print(\"indptr - \", len(X_test.indptr))\n",
    "#    print(\"data - \", len(X_test.data))\n",
    "    \n",
    "#    print(dir(X_test))\n",
    "#    print(\"X_ARRAY \", X_test._get_arrayXarray(0, 529))\n",
    "    \n",
    "    \n",
    "    if coef_show == 1: \n",
    "        w = feature_model.get_feature_names()\n",
    "        coef = clf.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print('Top 10 positive features (variables)')\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print('Top 10 negative features (variables)')        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "       \n",
    "    return X_test, clf_pred\n",
    "\n",
    "xtest, pred = model_fit(X, y, tfidf,LogisticRegression(),coef_show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 1000\n",
      "accuracy of the model:  0.9221666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.38      0.52       660\n",
      "           1       0.93      0.99      0.96      5340\n",
      "\n",
      "    accuracy                           0.92      6000\n",
      "   macro avg       0.87      0.69      0.74      6000\n",
      "weighted avg       0.92      0.92      0.91      6000\n",
      "\n",
      "\n",
      "Top 10 positive features (variables)\n",
      "      Word  Coefficient\n",
      "     great    13.299884\n",
      "      love    11.054383\n",
      "      best     8.156580\n",
      "      good     7.800511\n",
      "      easy     7.735733\n",
      "     clean     7.719841\n",
      "    better     5.808192\n",
      "     loved     5.688351\n",
      "      nice     5.268984\n",
      " excellent     5.121848\n",
      "   awesome     4.898837\n",
      "   perfect     4.861898\n",
      "  favorite     4.555234\n",
      "   enjoyed     4.373794\n",
      "   amazing     4.364436\n",
      "      free     3.939587\n",
      " wonderful     3.916948\n",
      "    really     3.575024\n",
      "     handy     3.529437\n",
      "     happy     3.373818\n",
      "\n",
      "Top 10 negative features (variables)\n",
      "          Word  Coefficient\n",
      "          base    -1.578752\n",
      " unfortunately    -1.630364\n",
      " disappointing    -1.851355\n",
      "           sad    -2.030757\n",
      "       chicken    -2.034986\n",
      "         crazy    -2.535949\n",
      "      resident    -2.611503\n",
      "          hate    -3.260024\n",
      "         wrong    -3.262962\n",
      "          cold    -3.268827\n",
      "         worst    -3.655030\n",
      "           bad    -3.925396\n",
      "          evil    -4.017543\n",
      "         dirty    -4.033550\n",
      "         awful    -4.161197\n",
      "         nasty    -4.319006\n",
      "      horrible    -4.578781\n",
      "  disappointed    -4.636527\n",
      "          sick    -4.697851\n",
      "      terrible    -4.804326\n"
     ]
    }
   ],
   "source": [
    "xtest, pred = model_fit(X, y, tfidf,LogisticRegression(),coef_show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 529)\t0.22241595149271842\n",
      "  (0, 47)\t0.20964319801245335\n",
      "  (0, 720)\t0.696980923623149\n",
      "  (0, 771)\t0.21593130586186834\n",
      "  (0, 90)\t0.40026789622812714\n",
      "  (0, 969)\t0.1885671404031856\n",
      "  (0, 371)\t0.16567427089889267\n",
      "  (0, 511)\t0.1772086562204112\n",
      "  (0, 940)\t0.1333247534125354\n",
      "  (0, 619)\t0.20415080720516499\n",
      "  (0, 61)\t0.11974647057071268\n",
      "  (0, 343)\t0.13457303762618536\n",
      "  (0, 832)\t0.16627431734861037\n",
      "  (1, 569)\t0.24218436278559\n",
      "  (1, 154)\t0.6098511233084832\n",
      "  (1, 526)\t0.4614886748852459\n",
      "  (1, 619)\t0.5597691993889182\n",
      "  (1, 524)\t0.20764148956715778\n",
      "  (2, 902)\t0.6130275606318966\n",
      "  (2, 859)\t0.6486652086683559\n",
      "  (2, 677)\t0.22152244726222683\n",
      "  (2, 147)\t0.22152244726222683\n",
      "  (2, 718)\t0.22001360570007655\n",
      "  (2, 524)\t0.23849587206847778\n",
      "  (3, 110)\t0.5440276702573296\n",
      "  :\t:\n",
      "  (5998, 3)\t0.2557293834011859\n",
      "  (5998, 110)\t0.32355073600328416\n",
      "  (5998, 570)\t0.23649604270272198\n",
      "  (5998, 283)\t0.36865793862816465\n",
      "  (5998, 752)\t0.3047600169042265\n",
      "  (5998, 940)\t0.23511843058393603\n",
      "  (5998, 155)\t0.28812486505187546\n",
      "  (5998, 349)\t0.2819074974858267\n",
      "  (5998, 373)\t0.16730827781511823\n",
      "  (5999, 12)\t0.3192749461823155\n",
      "  (5999, 604)\t0.3298303678784822\n",
      "  (5999, 716)\t0.2921390567711925\n",
      "  (5999, 518)\t0.2562424789390703\n",
      "  (5999, 526)\t0.2722557084672369\n",
      "  (5999, 918)\t0.3336066968117455\n",
      "  (5999, 515)\t0.23451097384843822\n",
      "  (5999, 851)\t0.2614631239222619\n",
      "  (5999, 209)\t0.22386801280841728\n",
      "  (5999, 930)\t0.300739463750397\n",
      "  (5999, 381)\t0.12004800467867613\n",
      "  (5999, 248)\t0.2107872622419241\n",
      "  (5999, 673)\t0.13224594255094044\n",
      "  (5999, 702)\t0.2077509437145105\n",
      "  (5999, 786)\t0.23090401187009107\n",
      "  (5999, 927)\t0.12698435921265283\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(xtest)\n",
    "print(pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
