{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = pd.read_csv(\"classified_alerts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = set(alerts['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a.c.t.b.r.s.e.customexceptionhandler', 'o.s.w.c.httpservererrorexception.internalservererror', 'o.s.w.c.httpservererrorexception.gatewaytimeout', 'a.c.t.b.r.c.l.loggingaspect', 'a.c.t.b.r.s.m.fromtarget.targetresponsedata', 'a.c.t.b.r.s.e.customexceptionhandler.handlehttpstatuscodeexception', 'j.lang.nullpointerexception', 'o.json.jsonexception', 'o.s.w.c.httpservererrorexception.badgateway', 'c.f.j.d.e.unrecognizedpropertyexception.from', 'a.c.t.b.r.c.u.commonutils'}\n"
     ]
    }
   ],
   "source": [
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_lst = list(cls)\n",
    "class_lst.index(class_lst[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10912"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alerts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['appname', 'alertid', 'class', 'words'], dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alerts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class to number\n",
    "def category2Num(cat):\n",
    "    global class_lst\n",
    "    return class_lst.index(cat)\n",
    "    \n",
    "alerts['category_num'] = alerts['class'].apply(category2Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appname</th>\n",
       "      <th>alertid</th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spg-service-request-inbound-consumer</td>\n",
       "      <td>a1642502490828</td>\n",
       "      <td>a.c.t.b.r.s.e.customexceptionhandler</td>\n",
       "      <td>info actbrsecustomexceptionhandler  requestid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spg-service-request-inbound-consumer</td>\n",
       "      <td>a1642502490829</td>\n",
       "      <td>a.c.t.b.r.s.e.customexceptionhandler</td>\n",
       "      <td>info actbrsecustomexceptionhandler  customexce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spg-service-request-inbound-consumer</td>\n",
       "      <td>a1642502490838</td>\n",
       "      <td>o.s.w.c.httpservererrorexception.badgateway</td>\n",
       "      <td>oswchttpservererrorexceptionbadgateway 502 bad...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spg-service-request-inbound-consumer</td>\n",
       "      <td>a1642502490888</td>\n",
       "      <td>a.c.t.b.r.s.e.customexceptionhandler</td>\n",
       "      <td>info actbrsecustomexceptionhandler  customexce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spg-service-request-inbound-consumer</td>\n",
       "      <td>a1642502490889</td>\n",
       "      <td>a.c.t.b.r.s.e.customexceptionhandler</td>\n",
       "      <td>info actbrsecustomexceptionhandler  requestid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                appname         alertid  \\\n",
       "0  spg-service-request-inbound-consumer  a1642502490828   \n",
       "1  spg-service-request-inbound-consumer  a1642502490829   \n",
       "2  spg-service-request-inbound-consumer  a1642502490838   \n",
       "3  spg-service-request-inbound-consumer  a1642502490888   \n",
       "4  spg-service-request-inbound-consumer  a1642502490889   \n",
       "\n",
       "                                         class  \\\n",
       "0         a.c.t.b.r.s.e.customexceptionhandler   \n",
       "1         a.c.t.b.r.s.e.customexceptionhandler   \n",
       "2  o.s.w.c.httpservererrorexception.badgateway   \n",
       "3         a.c.t.b.r.s.e.customexceptionhandler   \n",
       "4         a.c.t.b.r.s.e.customexceptionhandler   \n",
       "\n",
       "                                               words  category_num  \n",
       "0  info actbrsecustomexceptionhandler  requestid ...             0  \n",
       "1  info actbrsecustomexceptionhandler  customexce...             0  \n",
       "2  oswchttpservererrorexceptionbadgateway 502 bad...             8  \n",
       "3  info actbrsecustomexceptionhandler  customexce...             0  \n",
       "4  info actbrsecustomexceptionhandler  requestid ...             0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alerts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in c:\\users\\kumaraguru\\appdata\\roaming\\python\\python38\\site-packages (from textblob) (3.6.1)\n",
      "Requirement already satisfied: regex in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.47.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.15.1)\n",
      "Requirement already satisfied: click in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from textblob import Word\n",
    "from wordcloud import WordCloud\n",
    "import textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['words', 'category_num'], dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alerts = alerts.drop(['appname', 'alertid', 'class'], axis=1)\n",
    "alerts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     4262\n",
       "5     3595\n",
       "9     1287\n",
       "0      544\n",
       "1      340\n",
       "10     272\n",
       "8      204\n",
       "6      136\n",
       "2      136\n",
       "7       68\n",
       "3       68\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alerts['category_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = alerts['words']\n",
    "y = alerts['category_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        info actbrsecustomexceptionhandler  requestid ...\n",
      "1        info actbrsecustomexceptionhandler  customexce...\n",
      "2        oswchttpservererrorexceptionbadgateway 502 bad...\n",
      "3        info actbrsecustomexceptionhandler  customexce...\n",
      "4        info actbrsecustomexceptionhandler  requestid ...\n",
      "                               ...                        \n",
      "10907    cfjdexcunrecognizedpropertyexception unrecogni...\n",
      "10908    warn oswsmmaexceptionhandlerexceptionresolver ...\n",
      "10909    cfjdexcunrecognizedpropertyexception unrecogni...\n",
      "10910    cfjdexcunrecognizedpropertyexception unrecogni...\n",
      "10911    warn oswsmmaexceptionhandlerexceptionresolver ...\n",
      "Name: words, Length: 10912, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_stop_words = set(['info', 'of', 'and', 'cannot', 'warn', 'is', 'not', 'out', 'doctype', 'html', 'failed', 'failure', \\\n",
    "                     'handle', 'request', 'response', 'throwing', 'line', 'get', 'exception', 'detail', 'details', \\\n",
    "                     'be', 'to', 'in', 'public', 'throws', 'known', 'at', 'from', 'with', 'class', 'marked', 'as', \n",
    "                     'it', 'this', 'return', 'returning', 'notfound', 'type', 'title'])\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= my_stop_words)\n",
    "\n",
    "X = tfidf.fit_transform([\"this is an apple oswclientHttpServerErrorExceptionBadGateway that was cider\", \\\n",
    "                              \"this is and actbrseCustomExceptionHandler\",\\\n",
    "                              \"cfjdeUnrecognizedPropertyException Unrecognized field error class actbrsmfromtargetTargetResponseData not marked as ignorable 4 known properties status code message incidentId\"\\\n",
    "                             ])\n",
    "idf_values = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "\n",
    "#### printing the tfidf vectors\n",
    "print(X)\n",
    "\n",
    "#### printing the vocabulary\n",
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info actbrsecustomexceptionhandler  requestid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>info actbrsecustomexceptionhandler  customexce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oswchttpservererrorexceptionbadgateway 502 bad...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>info actbrsecustomexceptionhandler  customexce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>info actbrsecustomexceptionhandler  requestid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  category_num\n",
       "0  info actbrsecustomexceptionhandler  requestid ...             0\n",
       "1  info actbrsecustomexceptionhandler  customexce...             0\n",
       "2  oswchttpservererrorexceptionbadgateway 502 bad...             8\n",
       "3  info actbrsecustomexceptionhandler  customexce...             0\n",
       "4  info actbrsecustomexceptionhandler  requestid ...             0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alerts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = set(['info', 'of', 'and', 'cannot', 'warn', 'is', 'not', 'out', 'doctype', 'html', \\\n",
    "                     'failed', 'failure', 'handle', 'request', 'response', 'throwing', 'line', 'get', \\\n",
    "                     'exception', 'detail', 'details', 'be', 'to', 'in', 'public', 'throws', 'known', \\\n",
    "                     'at', 'from', 'with', 'class', 'marked', 'as', 'it', 'this', 'return', 'returning', \\\n",
    "                     'notfound', 'type', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= my_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle class imbalance\n",
    "X_features = tfidf.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=67)\n",
    "sm = SMOTE()\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "X_test_smote, y_test_smote = sm.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, ml_model, coef_show):\n",
    "    classification = ml_model.fit(X_train_smote, y_train_smote)\n",
    "    classification_pred = classification.predict(X_test_smote)\n",
    "    accuracy = classification.score(X_test_smote, y_test_smote)\n",
    "    model_performance = classification_report(y_test_smote, classification_pred)\n",
    "    validation_pred_proba_grad = classification.predict_proba(X_test_smote)\n",
    "    #roc_auc = roc_auc_score(y_test_smote, validation_pred_proba_grad[:,1])\n",
    "    \n",
    "    #print(\"***** Accuracy of the classification model: \", accuracy, \" *******\")\n",
    "    #print('')\n",
    "    #print(model_performance)\n",
    "    #print('')\n",
    "    #print(\"***** ROC_AUC score: \", roc_auc, \" *******\")\n",
    "    #print(\"*************************************************\")\n",
    "    \n",
    "    if coef_show == 1:\n",
    "        featureNames = tfidf.get_feature_names()\n",
    "        coef = classification.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : featureNames, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print(\"************ Top 10 positive features (variables) ************\")\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print(\"************ Top 10 negative features (variables) ************\")        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Top 10 positive features (variables) ************\n",
      "                                Word  Coefficient\n",
      "                                 400     2.496726\n",
      "       actbrsecustomexceptionhandler     2.496726\n",
      "                          badrequest     2.496726\n",
      "                         deserialize     2.496726\n",
      "                       errorresource     2.496726\n",
      "                            instance     2.496726\n",
      "                          startarray     2.496726\n",
      "                               token     2.496726\n",
      "                         jlangstring     1.796090\n",
      "                           requestid     1.639439\n",
      "                                 404     1.289124\n",
      "              customexceptionhandler     1.289124\n",
      "                               found     1.289124\n",
      "               handlecustomexception     1.289124\n",
      "                             message     0.496281\n",
      "                              status     0.496281\n",
      "                            endpoint    -0.103568\n",
      "                          registered    -0.103568\n",
      "                                 the    -0.103568\n",
      " actbrsmfromtargettargetresponsedata    -0.303341\n",
      "\n",
      "************ Top 10 negative features (variables) ************\n",
      "                                       Word  Coefficient\n",
      "                                  character    -0.397852\n",
      "                                     string    -0.397852\n",
      "                               unterminated    -0.397852\n",
      "                                        502    -0.436721\n",
      "                                        bad    -0.436721\n",
      "                                    gateway    -0.436721\n",
      "                         actbrcucommonutils    -0.456292\n",
      "                                    central    -0.456292\n",
      "                                    service    -0.456292\n",
      "                                       cast    -0.505820\n",
      "                      omjavascriptundefined    -0.505820\n",
      "                  jlangnullpointerexception    -0.589014\n",
      "                                       null    -0.589014\n",
      "                                        504    -0.589014\n",
      " oswchttpservererrorexceptiongatewaytimeout    -0.589014\n",
      "     cfjdeunrecognizedpropertyexceptionfrom    -0.589014\n",
      "          unrecognizedpropertyexceptionjava    -0.589014\n",
      "                         ojsonjsonexception    -0.682398\n",
      "                    jlangclasscastexception    -0.684225\n",
      "                                      error    -0.847732\n"
     ]
    }
   ],
   "source": [
    "LRClassModel = class_balanced_model_fit(X_train_smote, y_train_smote, \n",
    "                                     X_test_smote, y_test_smote, \n",
    "                                     LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500),\n",
    "                                     coef_show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9559x62 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 61115 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test some random text for classification - Do reviews classification as good or bad sentiment. \n",
    "Xfeatu = tfidf.transform(\n",
    "['cfjdexcunrecognizedpropertyexception unrecognized field error class actbrsmfromtargettargetresponsedata not marked as ignorable 4 known properties status code message incidentid', \n",
    "'warn oswsmmaexceptionhandlerexceptionresolver  failure in exceptionhandler public oshttpresponseentity jlangobject actbrsecustomexceptionhandlerhandlehttpstatuscodeexception oswclienthttpstatuscodeexception throws jioioexception',\n",
    "'info actbrsecustomexceptionhandler  customexceptionhandler handlecustomexception is returning 404 notfound not found errorresource type title badrequest status 400 message cannot deserialize instance of jlangstring out of startarray token'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 0]\n"
     ]
    }
   ],
   "source": [
    "print(LRClassModel.predict(Xfeatu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF TELSTRA CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.7071067811865476\n",
      "  (0, 9)\t0.7071067811865476\n",
      "  (1, 0)\t1.0\n",
      "  (2, 7)\t0.33333333333333337\n",
      "  (2, 8)\t0.33333333333333337\n",
      "  (2, 4)\t0.33333333333333337\n",
      "  (2, 10)\t0.33333333333333337\n",
      "  (2, 1)\t0.33333333333333337\n",
      "  (2, 5)\t0.33333333333333337\n",
      "  (2, 6)\t0.33333333333333337\n",
      "  (2, 11)\t0.33333333333333337\n",
      "  (2, 2)\t0.33333333333333337\n",
      "{'oswclienthttpservererrorexceptionbadgateway': 9, 'cider': 3, 'actbrsecustomexceptionhandler': 0, 'cfjdeunrecognizedpropertyexception': 2, 'unrecognized': 11, 'field': 6, 'error': 5, 'actbrsmfromtargettargetresponsedata': 1, 'status': 10, 'code': 4, 'message': 8, 'incidentid': 7}\n"
     ]
    }
   ],
   "source": [
    "my_stop_words = set(['apple', 'and', 'this', 'is', 'an', 'that', 'was', 'as', 'known', 'class', 'not', \\\n",
    "                     'marked', 'properties', 'ignorable', 'marked'])\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=my_stop_words)\n",
    "X = vectorizer.fit_transform([\"this is an apple oswclientHttpServerErrorExceptionBadGateway that was cider\", \\\n",
    "                              \"this is and actbrseCustomExceptionHandler\",\\\n",
    "                              \"cfjdeUnrecognizedPropertyException Unrecognized field error class actbrsmfromtargetTargetResponseData not marked as ignorable 4 known properties status code message incidentId\"\\\n",
    "                             ])\n",
    "idf_values = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "\n",
    "# printing the tfidf vectors\n",
    "print(X)\n",
    "\n",
    "# printing the vocabulary\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n",
      "Counter({1: 334, 2: 334, 0: 332})\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.681 (0.042)\n"
     ]
    }
   ],
   "source": [
    "# evaluate multinomial logistic regression model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make a prediction with a multinomial logistic regression model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# define a single row of input data\n",
    "row = [1.89149379, -0.39847585, 1.63856893, 0.01647165, 1.51892395, -3.52651223, 1.80998823, 0.58810926, -0.02542177, -0.52835426]\n",
    "# predict the class label\n",
    "yhat = model.predict([row])\n",
    "# summarize the predicted class\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "row = [2.89149379, -1.39847585, 0.63856893, 1.01647165, 3.51892395, -1.52651223, 2.80998823, -0.58810926, 0.22542177, 0.62835426]\n",
    "# predict the class label\n",
    "yhat = model.predict([row])\n",
    "# summarize the predicted class\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "row = [-3.89149379, 1.39847585, -1.63856893, 3.01647165, 2.51892395, -4.52651223, -3.80998823, 0.68810926, -3.02542177, -3.52835426]\n",
    "# predict the class label\n",
    "yhat = model.predict([row])\n",
    "# summarize the predicted class\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "row = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "# predict the class label\n",
    "yhat = model.predict([row])\n",
    "# summarize the predicted class\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities: [0.16470456 0.50297138 0.33232406]\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities with a multinomial logistic regression model\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# define a single row of input data\n",
    "row = [1.89149379, -0.39847585, 1.63856893, 0.01647165, 1.51892395, -3.52651223, 1.80998823, 0.58810926, -0.02542177, -0.52835426]\n",
    "# predict a multinomial probability distribution\n",
    "yhat = model.predict_proba([row])\n",
    "# summarize the predicted probabilities\n",
    "print('Predicted Probabilities: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in c:\\users\\kumaraguru\\appdata\\roaming\\python\\python38\\site-packages (from textblob) (3.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.15.1)\n",
      "Requirement already satisfied: regex in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.47.0)\n",
      "Requirement already satisfied: click in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\kumaraguru\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from textblob import Word\n",
    "from wordcloud import WordCloud\n",
    "import textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets do some EDA. Load the data. Check for the missing values. Treat them. Impute if necessary or drop the fields. Get a sense of data imbalance too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(\"sample30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(reviews_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'brand', 'categories', 'manufacturer', 'name', 'reviews_date',\n",
      "       'reviews_didPurchase', 'reviews_doRecommend', 'reviews_rating',\n",
      "       'reviews_text', 'reviews_title', 'reviews_userCity',\n",
      "       'reviews_userProvince', 'reviews_username', 'user_sentiment'],\n",
      "      dtype='object')\n",
      "(30000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.columns)\n",
    "print(reviews_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need only the 'name', 'reviews_rating', 'reviews_text', 'reviews_username' and 'user_sentiment'. Rest of the columns can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.drop(['id', 'brand', 'categories', 'manufacturer', \n",
    "                              'reviews_date', 'reviews_didPurchase', 'reviews_doRecommend', \n",
    "                              'reviews_title', 'reviews_userCity', 'reviews_userProvince'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>5</td>\n",
       "      <td>I got this conditioner with Influenster to try...</td>\n",
       "      <td>laurasnchz</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love it , I received this for review purpose...</td>\n",
       "      <td>scarlepadilla</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>5</td>\n",
       "      <td>First of all I love the smell of this product....</td>\n",
       "      <td>liviasuexo</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>5</td>\n",
       "      <td>I received this through Influenster and will n...</td>\n",
       "      <td>ktreed95</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>5</td>\n",
       "      <td>I received this product complimentary from inf...</td>\n",
       "      <td>kcoopxoxo</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  reviews_rating  \\\n",
       "0              Pink Friday: Roman Reloaded Re-Up (w/dvd)               5   \n",
       "1             Lundberg Organic Cinnamon Toast Rice Cakes               5   \n",
       "2             Lundberg Organic Cinnamon Toast Rice Cakes               5   \n",
       "3                       K-Y Love Sensuality Pleasure Gel               1   \n",
       "4                       K-Y Love Sensuality Pleasure Gel               1   \n",
       "...                                                  ...             ...   \n",
       "29995  L'or233al Paris Elvive Extraordinary Clay Reba...               5   \n",
       "29996  L'or233al Paris Elvive Extraordinary Clay Reba...               5   \n",
       "29997  L'or233al Paris Elvive Extraordinary Clay Reba...               5   \n",
       "29998  L'or233al Paris Elvive Extraordinary Clay Reba...               5   \n",
       "29999  L'or233al Paris Elvive Extraordinary Clay Reba...               5   \n",
       "\n",
       "                                            reviews_text reviews_username  \\\n",
       "0      i love this album. it's very good. more to the...           joshua   \n",
       "1      Good flavor. This review was collected as part...        dorothy w   \n",
       "2                                           Good flavor.        dorothy w   \n",
       "3      I read through the reviews on here before look...          rebecca   \n",
       "4      My husband bought this gel for us. The gel cau...        walker557   \n",
       "...                                                  ...              ...   \n",
       "29995  I got this conditioner with Influenster to try...       laurasnchz   \n",
       "29996  I love it , I received this for review purpose...    scarlepadilla   \n",
       "29997  First of all I love the smell of this product....       liviasuexo   \n",
       "29998  I received this through Influenster and will n...         ktreed95   \n",
       "29999  I received this product complimentary from inf...        kcoopxoxo   \n",
       "\n",
       "      user_sentiment  \n",
       "0           Positive  \n",
       "1           Positive  \n",
       "2           Positive  \n",
       "3           Negative  \n",
       "4           Negative  \n",
       "...              ...  \n",
       "29995       Positive  \n",
       "29996       Positive  \n",
       "29997       Positive  \n",
       "29998       Positive  \n",
       "29999       Positive  \n",
       "\n",
       "[30000 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are ~25K users in in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "byamazon customer    41\n",
       "mike                 41\n",
       "chris                32\n",
       "lisa                 16\n",
       "rick                 15\n",
       "                     ..\n",
       "ssttaarr              1\n",
       "arty                  1\n",
       "touthao               1\n",
       "crysteelwiech         1\n",
       "newmommy25            1\n",
       "Name: reviews_username, Length: 24914, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['reviews_username'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 271 unique products in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total                         8545\n",
       "Godzilla 3d Includes Digital Copy Ultraviolet 3d/2d Blu-Ray/dvd                   3325\n",
       "Clorox Disinfecting Bathroom Cleaner                                              2039\n",
       "L'or233al Paris Elvive Extraordinary Clay Rebalancing Conditioner - 12.6 Fl Oz    1186\n",
       "Planes: Fire Rescue (2 Discs) (includes Digital Copy) (blu-Ray/dvd)               1143\n",
       "                                                                                  ... \n",
       "Citrus Magic Instant Spot & Stain Remover                                            1\n",
       "Pacific Natural Foods Organic Beef Broth                                             1\n",
       "Black Sister's Revenge (dvd)                                                         1\n",
       "Roommates No Place Like Home Peel Stick Wall Decals                                  1\n",
       "Sloan Royal Urinal Flush Valve, 1.0 Gpf, Royal 186-1                                 1\n",
       "Name: name, Length: 271, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['reviews_username'] = reviews_df['reviews_username'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  reviews_rating  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)               5   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes               5   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes               5   \n",
       "3            K-Y Love Sensuality Pleasure Gel               1   \n",
       "4            K-Y Love Sensuality Pleasure Gel               1   \n",
       "\n",
       "                                        reviews_text reviews_username  \\\n",
       "0  i love this album. it's very good. more to the...           joshua   \n",
       "1  Good flavor. This review was collected as part...        dorothy w   \n",
       "2                                       Good flavor.        dorothy w   \n",
       "3  I read through the reviews on here before look...          rebecca   \n",
       "4  My husband bought this gel for us. The gel cau...        walker557   \n",
       "\n",
       "  user_sentiment  \n",
       "0       Positive  \n",
       "1       Positive  \n",
       "2       Positive  \n",
       "3       Negative  \n",
       "4       Negative  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are no empty review rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df['reviews_text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are no empty review ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df['reviews_rating'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are no records to be imputed or dropped because all of them seem to have values. We don't have to drop records for products. At the same time, the below list shows that there are around ~50 products that have just 1 reviews. These can be dropped as they qualify to be outliers, but we choose to retain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sloan Royal Urinal Flush Valve, 1.0 Gpf, Royal 186-1                                                    1\n",
       "Disney174 Jake And The Neverland Pirates 4 Piece Bedding Set - Toddler                                  1\n",
       "Every Man Jack Pomade Signature Mint Scent                                                              1\n",
       "Clorox Ultimate Care Premium Bleach                                                                     1\n",
       "Pearhead Id Bracelet Frame                                                                              1\n",
       "Noosa Honey Yogurt                                                                                      1\n",
       "Wedding Wishes Wedding Guest Book                                                                       1\n",
       "Iman Luxury Moisturizing Lipstick, Black Brandy 006                                                     1\n",
       "La Tortilla Factory Hand Made Style Tortillas Flour                                                     1\n",
       "Pink Friday: Roman Reloaded Re-Up (w/dvd)                                                               1\n",
       "Fantasy Fields Lil' Sports Fan Step Stool - Teamson                                                     1\n",
       "Walkers Stem Ginger Shortbread                                                                          1\n",
       "Lite Source Basic Ii 1-Lt Floor Lamp - Dark Bronze                                                      1\n",
       "Tostitos Original Restaurant Style Tortilla Chips                                                       1\n",
       "Kenroy Home Table Lamp - Chrome                                                                         1\n",
       "Sea Gull Lighting Ceiling Fan - White                                                                   1\n",
       "42 Dual Drop Leaf Table with 2 Madrid Chairs\"                                                           1\n",
       "Cal Lighting Led Dark Bronze Finish Metal Piano Lamp                                                    1\n",
       "Stonyfield Yobaby Peach & Pear Yogurt 4oz 6 Ct                                                          1\n",
       "Germ Guardian174 Elite 3-In-1 Pet Pure True Hepa Air Purifier Ac4300bptca                               1\n",
       "Southern Enterprises Archer Fold-Away Home Bar in Walnut                                                1\n",
       "Various - Country's Greatest Gospel:Gold Ed (cd)                                                        1\n",
       "Wallmount Server Cabinet (450mm, 9 RU)                                                                  1\n",
       "Elvis Presley - Girl Happy (cd)                                                                         1\n",
       "Roommates No Place Like Home Peel Stick Wall Decals                                                     1\n",
       "Pocket Watch Wall Clock Distressed Black - Yosemite Home Decor174                                       1\n",
       "Avery174 11-1/4 X 9-1/4 Index Maker Extra Wide Label Dividers With 5 Tab - Clear (5 Sets Per Pack)      1\n",
       "Black Sister's Revenge (dvd)                                                                            1\n",
       "Pacific Natural Foods Organic Beef Broth                                                                1\n",
       "Citrus Magic Instant Spot & Stain Remover                                                               1\n",
       "Candy Pink Plastic Cups, 20 pk                                                                          1\n",
       "Lite Source Reiko 1 Light Table Lamp - Orange                                                           1\n",
       "Progresso Traditional Chicken Rice With Vegetables Soup                                                 1\n",
       "5302050 15/16 FCT/HOSE ADAPTOR                                                                          1\n",
       "Progresso Traditional Meatball & Rice Soup                                                              1\n",
       "Bodycology Nourishing Body Cream, Pretty In Paris                                                       1\n",
       "Sunflower Swag With Metal Frame - Nearly Natural                                                        1\n",
       "Carson-Dellosa Publishing Photographic Learning Cards Boxed Set, Nouns/verbs/adjectives, Grades K-12    1\n",
       "Udi's Pepperoni Pizza                                                                                   1\n",
       "Heinz Tomato Ketchup, 38oz                                                                              1\n",
       "Herr's Baked Cheese Curls                                                                               1\n",
       "Wilton Black Dots Standard Baking Cups                                                                  1\n",
       "JNH Lifestyles Goldstar 3 Person FAR Infrared Sauna                                                     1\n",
       "Scotty Mini Double Ended Extender                                                                       1\n",
       "Blue Anchor Design Throw Pillow (18x18) - Rizzy Home                                                    1\n",
       "Craft Punch Giga Scallop Circle 45 24687534 To 334                                                      1\n",
       "Sea Gull Lighting One Light Wall/bath/vanity-Brushed Nickel                                             1\n",
       "High-Dome Floor Door Stop                                                                               1\n",
       "Greyson Vintage Industrial Occasional Cocktail Coffee Table - Antique Bronze - Baxton Studio            1\n",
       "Smead174 Recycled Letter Size Manila File Backs W/prong Fasteners, 2 Capacity, 100/box                  2\n",
       "King Ralph (dvd)                                                                                        2\n",
       "Lundberg Organic Cinnamon Toast Rice Cakes                                                              2\n",
       "Smead174 2 1/4 Inch Accordion Expansion Wallet, Poly, Letter, Translucent Green                         2\n",
       "Nature's Path Chunky Chocolate Peanut Chewy Granola Bars                                                2\n",
       "Charcoal Stone Toothbrush Holder Gray                                                                   2\n",
       "Sea Gull Lighting Holman One Light Wall/bath Sconce - Brushed Nickel                                    2\n",
       "RC Cola, 12oz                                                                                           2\n",
       "Stacy's Garden Veggie Medley Pita Chips                                                                 2\n",
       "Coola Organic Sunscreen Classic Face Cucumber SPF 30                                                    2\n",
       "Annie's Homegrown Deluxe Elbows & Four Cheese Sauce                                                     2\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = reviews_df['name'].value_counts().sort_values()[0:60]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i love this album. it's very good. more to the...\n",
       "1        Good flavor. This review was collected as part...\n",
       "2                                             Good flavor.\n",
       "3        I read through the reviews on here before look...\n",
       "4        My husband bought this gel for us. The gel cau...\n",
       "                               ...                        \n",
       "29995    I got this conditioner with Influenster to try...\n",
       "29996    I love it , I received this for review purpose...\n",
       "29997    First of all I love the smell of this product....\n",
       "29998    I received this through Influenster and will n...\n",
       "29999    I received this product complimentary from inf...\n",
       "Name: reviews_text, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['reviews_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the reviews have any hypertext references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29994\n",
       "1        6\n",
       "Name: reviews_text, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkHyperText(x):\n",
    "    if x.find(\"http:\") == -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "http = reviews_df['reviews_text'].apply(checkHyperText)\n",
    "http.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a few, hyperlinks, but they are descriptive. Remove the hyperlinks in the reviews text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i love this album. it's very good. more to the...\n",
       "1        Good flavor. This review was collected as part...\n",
       "2                                             Good flavor.\n",
       "3        I read through the reviews on here before look...\n",
       "4        My husband bought this gel for us. The gel cau...\n",
       "                               ...                        \n",
       "29995    I got this conditioner with Influenster to try...\n",
       "29996    I love it , I received this for review purpose...\n",
       "29997    First of all I love the smell of this product....\n",
       "29998    I received this through Influenster and will n...\n",
       "29999    I received this product complimentary from inf...\n",
       "Name: reviews_tokenized, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['reviews_tokenized'] = reviews_df['reviews_text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "reviews_df['reviews_tokenized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I applied Lemmatization and found that it had a negative impact on the review classification and the accuracy came down. I choose to convert contractions programmatically - explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i love this album. it is very good. more to th...\n",
       "1        Good flavor. This review was collected as part...\n",
       "2                                             Good flavor.\n",
       "3        I read through the reviews on here before look...\n",
       "4        My husband bought this gel for us. The gel cau...\n",
       "                               ...                        \n",
       "29995    I got this conditioner with Influenster to try...\n",
       "29996    I love it , I received this for review purpose...\n",
       "29997    First of all I love the smell of this product....\n",
       "29998    I received this through Influenster and will n...\n",
       "29999    I received this product complimentary from inf...\n",
       "Name: reviews_tokenized, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_contractions(s):\n",
    "    s = re.sub(r\"won't\", \"will not\", s)\n",
    "    s = re.sub(r\"would't\", \"would not\", s)\n",
    "    s = re.sub(r\"could't\", \"could not\", s)\n",
    "    s = re.sub(r\"\\'d\", \" would\", s)\n",
    "    s = re.sub(r\"can\\'t\", \"can not\", s)\n",
    "    s = re.sub(r\"n\\'t\", \" not\", s)\n",
    "    s= re.sub(r\"\\'re\", \" are\", s)\n",
    "    s = re.sub(r\"\\'s\", \" is\", s)\n",
    "    s = re.sub(r\"\\'ll\", \" will\", s)\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    s = re.sub(r\"\\'ve\", \" have\", s)\n",
    "    s = re.sub(r\"\\'m\", \" am\", s)\n",
    "    return s\n",
    "\n",
    "reviews_df['reviews_tokenized'] =reviews_df['reviews_tokenized'].apply(lambda x:expand_contractions(x))\n",
    "reviews_df['reviews_tokenized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the reviews text and retain only the English alphabet - words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i love this album it is very good more to the ...\n",
       "1        good flavor this review was collected as part ...\n",
       "2                                              good flavor\n",
       "3        i read through the reviews on here before look...\n",
       "4        my husband bought this gel for us the gel caus...\n",
       "                               ...                        \n",
       "29995    i got this conditioner with influenster to try...\n",
       "29996    i love it i received this for review purposes ...\n",
       "29997    first of all i love the smell of this product ...\n",
       "29998    i received this through influenster and will n...\n",
       "29999    i received this product complimentary from inf...\n",
       "Name: reviews_tokenized, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize the review text to words\n",
    "reg = re.compile('[^a-zA-Z]+')\n",
    "def tokenizeReview(text):\n",
    "    text = text.lower()\n",
    "    text = reg.sub(' ', text).strip()\n",
    "    return text\n",
    "\n",
    "reviews_df['reviews_tokenized'] = reviews_df['reviews_tokenized'].apply(tokenizeReview)\n",
    "reviews_df['reviews_tokenized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the original reviews text and pre-processed reviews text that will be fed to the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>i love this album it is very good more to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>good flavor this review was collected as part ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>good flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>i read through the reviews on here before look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>my husband bought this gel for us the gel caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>I got this conditioner with Influenster to try...</td>\n",
       "      <td>i got this conditioner with influenster to try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>I love it , I received this for review purpose...</td>\n",
       "      <td>i love it i received this for review purposes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>First of all I love the smell of this product....</td>\n",
       "      <td>first of all i love the smell of this product ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>I received this through Influenster and will n...</td>\n",
       "      <td>i received this through influenster and will n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>I received this product complimentary from inf...</td>\n",
       "      <td>i received this product complimentary from inf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviews_text  \\\n",
       "0      i love this album. it's very good. more to the...   \n",
       "1      Good flavor. This review was collected as part...   \n",
       "2                                           Good flavor.   \n",
       "3      I read through the reviews on here before look...   \n",
       "4      My husband bought this gel for us. The gel cau...   \n",
       "...                                                  ...   \n",
       "29995  I got this conditioner with Influenster to try...   \n",
       "29996  I love it , I received this for review purpose...   \n",
       "29997  First of all I love the smell of this product....   \n",
       "29998  I received this through Influenster and will n...   \n",
       "29999  I received this product complimentary from inf...   \n",
       "\n",
       "                                       reviews_tokenized  \n",
       "0      i love this album it is very good more to the ...  \n",
       "1      good flavor this review was collected as part ...  \n",
       "2                                            good flavor  \n",
       "3      i read through the reviews on here before look...  \n",
       "4      my husband bought this gel for us the gel caus...  \n",
       "...                                                  ...  \n",
       "29995  i got this conditioner with influenster to try...  \n",
       "29996  i love it i received this for review purposes ...  \n",
       "29997  first of all i love the smell of this product ...  \n",
       "29998  i received this through influenster and will n...  \n",
       "29999  i received this product complimentary from inf...  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[['reviews_text', 'reviews_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.drop(['reviews_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i love this album it is very good more to the ...\n",
       "1    good flavor this review was collected as part ...\n",
       "2                                          good flavor\n",
       "3    i read through the reviews on here before look...\n",
       "4    my husband bought this gel for us the gel caus...\n",
       "Name: reviews_tokenized, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['reviews_tokenized'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_sentiment column as 89% positive reviews and just 11% negative reviews. This is huge imbalance in data that would affect the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    26632\n",
       "Negative     3367\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['user_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'positive' to 1 and 'negative' to 0\n",
    "def sentiment2Number(txt):\n",
    "    if str(txt).lower() == 'positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X = reviews_df['reviews_tokenized']\n",
    "y = reviews_df['user_sentiment'].apply(sentiment2Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "29995    1\n",
       "29996    1\n",
       "29997    1\n",
       "29998    1\n",
       "29999    1\n",
       "Name: user_sentiment, Length: 30000, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TF-IDF Vectorizer and leverage the built-in stop_words functionality and remove stop words too. Use the max_features as a hyper-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As indicated earlier, we have a highly skewed data-set, which is not in balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26632\n",
       "0     3368\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Indicates class imbalance\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data split.\n",
    "### Use SMOTE to fix class imbalance before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle class imbalance\n",
    "X_features = tfidf.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=67)\n",
    "sm = SMOTE()\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "X_test_smote, y_test_smote = sm.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core function of the project. Fit the tf-idf vectorized features into the text classification model. Evaluate it with the ROC - AUC method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balanced_model_fit(X_train_smote, y_train_smote, X_test_smote, y_test_smote, ml_model, coef_show):\n",
    "    classification = ml_model.fit(X_train_smote, y_train_smote)\n",
    "    classification_pred = classification.predict(X_test_smote)\n",
    "    accuracy = classification.score(X_test_smote, y_test_smote)\n",
    "    model_performance = classification_report(y_test_smote, classification_pred)\n",
    "    validation_pred_proba_grad = classification.predict_proba(X_test_smote)\n",
    "    roc_auc = roc_auc_score(y_test_smote, validation_pred_proba_grad[:,1])\n",
    "    \n",
    "    print(\"***** Accuracy of the classification model: \", accuracy, \" *******\")\n",
    "    print('')\n",
    "    print(model_performance)\n",
    "    print('')\n",
    "    print(\"***** ROC_AUC score: \", roc_auc, \" *******\")\n",
    "    print(\"*************************************************\")\n",
    "    \n",
    "    if coef_show == 1:\n",
    "        featureNames = tfidf.get_feature_names()\n",
    "        coef = classification.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : featureNames, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print(\"************ Top 10 positive features (variables) ************\")\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print(\"************ Top 10 negative features (variables) ************\")        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Model Building, with 3 models - Logistic Regression, Bayes and Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Logistic Regression as the classification model and evaluate.\n",
    "#### Accuracy is 94% and AUC is 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Accuracy of the classification model:  0.9416977611940298  *******\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      5360\n",
      "           1       0.96      0.92      0.94      5360\n",
      "\n",
      "    accuracy                           0.94     10720\n",
      "   macro avg       0.94      0.94      0.94     10720\n",
      "weighted avg       0.94      0.94      0.94     10720\n",
      "\n",
      "\n",
      "***** ROC_AUC score:  0.9822858480452218  *******\n",
      "*************************************************\n",
      "\n",
      "************ Top 10 positive features (variables) ************\n",
      "      Word  Coefficient\n",
      "     great    17.780394\n",
      "      love    15.116278\n",
      "      best    12.266600\n",
      "      good    11.035214\n",
      "      easy    10.771146\n",
      "     clean    10.731221\n",
      "    better     9.063239\n",
      "     loved     8.598145\n",
      "      nice     8.314935\n",
      " excellent     8.125357\n",
      "   perfect     7.879954\n",
      "   awesome     7.312009\n",
      "   amazing     7.163275\n",
      "   enjoyed     6.968860\n",
      "  favorite     6.916870\n",
      " wonderful     6.270315\n",
      "      free     6.074108\n",
      "     handy     5.948584\n",
      "    action     5.575692\n",
      "     fresh     5.575606\n",
      "\n",
      "************ Top 10 negative features (variables) ************\n",
      "          Word  Coefficient\n",
      "          poor    -1.992059\n",
      " disappointing    -2.395613\n",
      "         crazy    -2.459916\n",
      " unfortunately    -2.790357\n",
      "      resident    -3.088036\n",
      "           sad    -3.298941\n",
      "          base    -3.478232\n",
      "         wrong    -3.536252\n",
      "          cold    -3.583337\n",
      "         dirty    -4.327427\n",
      "          hate    -4.785036\n",
      "         worst    -4.790985\n",
      "          evil    -4.928444\n",
      "           bad    -4.990064\n",
      "         nasty    -5.501614\n",
      "          sick    -6.078577\n",
      "         awful    -6.248576\n",
      "  disappointed    -6.376797\n",
      "      horrible    -6.543522\n",
      "      terrible    -7.594675\n"
     ]
    }
   ],
   "source": [
    "LRClassModel = class_balanced_model_fit(X_train_smote, y_train_smote, \n",
    "                                     X_test_smote, y_test_smote, \n",
    "                                     LogisticRegression(solver='lbfgs', max_iter=500),\n",
    "                                     coef_show=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a few sentences using the above positive and negative words and evaluate if they are classified correctly with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Test some random text for classification - Do reviews classification as good or bad sentiment. \n",
    "Xfeatu = tfidf.transform(['i love this album it is very good', \n",
    "                          'an easy to use product',\n",
    "                          'an awful product',\n",
    "                          'they gave a free gift with the product',\n",
    "                          'i went crazy after applying the lotion'])\n",
    "print(LRClassModel.predict(Xfeatu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Part A - User-based collaborative recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do reviews classification as good or bad sentiment. \n",
    "tfidfFeatures = tfidf.transform(reviews_df.reviews_tokenized)\n",
    "sentcls = LRClassModel.predict(tfidfFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END OF FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
